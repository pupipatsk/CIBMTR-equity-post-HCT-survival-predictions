{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d734aef9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T17:18:29.952444Z",
     "iopub.status.busy": "2025-02-02T17:18:29.952010Z",
     "iopub.status.idle": "2025-02-02T17:18:29.984227Z",
     "shell.execute_reply": "2025-02-02T17:18:29.983025Z"
    },
    "papermill": {
     "duration": 0.038567,
     "end_time": "2025-02-02T17:18:29.986287",
     "exception": false,
     "start_time": "2025-02-02T17:18:29.947720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ### Implementation of 'from lifelines.utils import concordance_index'\n",
    "# # because of no internet access(!pip install lifelines) when inferencing with kaggle\n",
    "# # src: https://github.com/CamDavidsonPilon/lifelines/blob/47afb1c1a272b0f03e0c8ca00e63df27eb2a0560/lifelines/utils/concordance.py\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# class _BTree:\n",
    "\n",
    "#     \"\"\"A simple balanced binary order statistic tree to help compute the concordance.\n",
    "\n",
    "#     When computing the concordance, we know all the values the tree will ever contain. That\n",
    "#     condition simplifies this tree a lot. It means that instead of crazy AVL/red-black shenanigans\n",
    "#     we can simply do the following:\n",
    "\n",
    "#     - Store the final tree in flattened form in an array (so node i's children are 2i+1, 2i+2)\n",
    "#     - Additionally, store the current size of each subtree in another array with the same indices\n",
    "#     - To insert a value, just find its index, increment the size of the subtree at that index and\n",
    "#       propagate\n",
    "#     - To get the rank of an element, you add up a bunch of subtree counts\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, values):\n",
    "#         \"\"\"\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         values: list\n",
    "#             List of sorted (ascending), unique values that will be inserted.\n",
    "#         \"\"\"\n",
    "#         self._tree = self._treeify(values)\n",
    "#         self._counts = np.zeros_like(self._tree, dtype=int)\n",
    "\n",
    "#     @staticmethod\n",
    "#     def _treeify(values):\n",
    "#         \"\"\"Convert the np.ndarray `values` into a complete balanced tree.\n",
    "\n",
    "#         Assumes `values` is sorted ascending. Returns a list `t` of the same length in which t[i] >\n",
    "#         t[2i+1] and t[i] < t[2i+2] for all i.\"\"\"\n",
    "#         if len(values) == 1:  # this case causes problems later\n",
    "#             return values\n",
    "#         tree = np.empty_like(values)\n",
    "#         # Tree indices work as follows:\n",
    "#         # 0 is the root\n",
    "#         # 2n+1 is the left child of n\n",
    "#         # 2n+2 is the right child of n\n",
    "#         # So we now rearrange `values` into that format...\n",
    "\n",
    "#         # The first step is to remove the bottom row of leaves, which might not be exactly full\n",
    "#         last_full_row = int(np.log2(len(values) + 1) - 1)\n",
    "#         len_ragged_row = len(values) - (2 ** (last_full_row + 1) - 1)\n",
    "#         if len_ragged_row > 0:\n",
    "#             bottom_row_ix = np.s_[: 2 * len_ragged_row : 2]\n",
    "#             tree[-len_ragged_row:] = values[bottom_row_ix]\n",
    "#             values = np.delete(values, bottom_row_ix)\n",
    "\n",
    "#         # Now `values` is length 2**n - 1, so can be packed efficiently into a tree\n",
    "#         # Last row of nodes is indices 0, 2, ..., 2**n - 2\n",
    "#         # Second-last row is indices 1, 5, ..., 2**n - 3\n",
    "#         # nth-last row is indices (2**n - 1)::(2**(n+1))\n",
    "#         values_start = 0\n",
    "#         values_space = 2\n",
    "#         values_len = 2 ** last_full_row\n",
    "#         while values_start < len(values):\n",
    "#             tree[values_len - 1 : 2 * values_len - 1] = values[values_start::values_space]\n",
    "#             values_start += int(values_space / 2)\n",
    "#             values_space *= 2\n",
    "#             values_len = int(values_len / 2)\n",
    "#         return tree\n",
    "\n",
    "#     def insert(self, value):\n",
    "#         \"\"\"Insert an occurrence of `value` into the btree.\"\"\"\n",
    "#         i = 0\n",
    "#         n = len(self._tree)\n",
    "#         while i < n:\n",
    "#             cur = self._tree[i]\n",
    "#             self._counts[i] += 1\n",
    "#             if value < cur:\n",
    "#                 i = 2 * i + 1\n",
    "#             elif value > cur:\n",
    "#                 i = 2 * i + 2\n",
    "#             else:\n",
    "#                 return\n",
    "#         raise ValueError(\"Value %s not contained in tree.\" \"Also, the counts are now messed up.\" % value)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return self._counts[0]\n",
    "\n",
    "#     def rank(self, value):\n",
    "#         \"\"\"Returns the rank and count of the value in the btree.\"\"\"\n",
    "#         i = 0\n",
    "#         n = len(self._tree)\n",
    "#         rank = 0\n",
    "#         count = 0\n",
    "#         while i < n:\n",
    "#             cur = self._tree[i]\n",
    "#             if value < cur:\n",
    "#                 i = 2 * i + 1\n",
    "#                 continue\n",
    "#             elif value > cur:\n",
    "#                 rank += self._counts[i]\n",
    "#                 # subtract off the right tree if exists\n",
    "#                 nexti = 2 * i + 2\n",
    "#                 if nexti < n:\n",
    "#                     rank -= self._counts[nexti]\n",
    "#                     i = nexti\n",
    "#                     continue\n",
    "#                 else:\n",
    "#                     return (rank, count)\n",
    "#             else:  # value == cur\n",
    "#                 count = self._counts[i]\n",
    "#                 lefti = 2 * i + 1\n",
    "#                 if lefti < n:\n",
    "#                     nleft = self._counts[lefti]\n",
    "#                     count -= nleft\n",
    "#                     rank += nleft\n",
    "#                     righti = lefti + 1\n",
    "#                     if righti < n:\n",
    "#                         count -= self._counts[righti]\n",
    "#                 return (rank, count)\n",
    "#         return (rank, count)\n",
    "\n",
    "# # -*- coding: utf-8 -*-\n",
    "\n",
    "# import numpy as np\n",
    "# # from lifelines.utils.btree import _BTree\n",
    "\n",
    "\n",
    "# def somers_d(event_times, x, event_observed=None) -> float:\n",
    "#     \"\"\"\n",
    "#     A measure of rank association between [-1, 1] between a censored variable, event_times,\n",
    "#     and another (uncensored) variable, x. -1 is strong anti-correlation, 1 is strong correlation.\n",
    "\n",
    "\n",
    "#     event_times: iterable\n",
    "#          a length-n iterable of observed survival times.\n",
    "#     x: iterable\n",
    "#         a length-n iterable to compare against\n",
    "#     event_observed: iterable, optional\n",
    "#         a length-n iterable censoring flags, 1 if observed, 0 if not. Default None assumes all observed.\n",
    "\n",
    "\n",
    "#     Examples\n",
    "#     --------\n",
    "#     .. code:: python\n",
    "#         from lifelines.datasets import load_rossi\n",
    "#         from lifelines.utils\n",
    "\n",
    "#         T, E = df['week'], df['arrest']\n",
    "#         x = df['age']\n",
    "#         somers_d(T, x, E)\n",
    "\n",
    "\n",
    "#     \"\"\"\n",
    "#     return 2 * concordance_index(event_times, x, event_observed) - 1\n",
    "\n",
    "\n",
    "# def concordance_index(event_times, predicted_scores, event_observed=None) -> float:\n",
    "#     \"\"\"\n",
    "#     Calculates the concordance index (C-index) between a series\n",
    "#     of event times and a predicted score. The first is the real survival times from\n",
    "#     the observational data, and the other is the predicted score from a model of some kind.\n",
    "\n",
    "#     The c-index is the average of how often a model says X is greater than Y when, in the observed\n",
    "#     data, X is indeed greater than Y. The c-index also handles how to handle censored values\n",
    "#     (obviously, if Y is censored, it's hard to know if X is truly greater than Y).\n",
    "\n",
    "\n",
    "#     The concordance index is a value between 0 and 1 where:\n",
    "\n",
    "#     - 0.5 is the expected result from random predictions,\n",
    "#     - 1.0 is perfect concordance and,\n",
    "#     - 0.0 is perfect anti-concordance (multiply predictions with -1 to get 1.0)\n",
    "\n",
    "#     The calculation internally done is\n",
    "\n",
    "#     >>> (pairs_correct + 0.5 * pairs_tied) / admissable_pairs\n",
    "\n",
    "#     where ``pairs_correct`` is the number of pairs s.t. if ``t_x > t_y``, then ``s_x > s_y``, pairs,\n",
    "#     ``pairs_tied`` is the number of pairs where ``s_x = s_y``, and ``admissable_pairs`` is all possible pairs. The subtleties\n",
    "#     are in how censored observation are handled (ex: not all pairs can be evaluated due to censoring).\n",
    "\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     event_times: iterable\n",
    "#          a length-n iterable of observed survival times.\n",
    "#     predicted_scores: iterable\n",
    "#         a length-n iterable of predicted scores - these could be survival times, or hazards, etc. See https://stats.stackexchange.com/questions/352183/use-median-survival-time-to-calculate-cph-c-statistic/352435#352435\n",
    "#     event_observed: iterable, optional\n",
    "#         a length-n iterable censoring flags, 1 if observed, 0 if not. Default None assumes all observed.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     c-index: float\n",
    "#       a value between 0 and 1.\n",
    "\n",
    "#     References\n",
    "#     -----------\n",
    "#     Harrell FE, Lee KL, Mark DB. Multivariable prognostic models: issues in\n",
    "#     developing models, evaluating assumptions and adequacy, and measuring and\n",
    "#     reducing errors. Statistics in Medicine 1996;15(4):361-87.\n",
    "\n",
    "#     Examples\n",
    "#     --------\n",
    "#     .. code:: python\n",
    "\n",
    "#         from lifelines.utils import concordance_index\n",
    "#         cph = CoxPHFitter().fit(df, 'T', 'E')\n",
    "#         concordance_index(df['T'], -cph.predict_partial_hazard(df), df['E'])\n",
    "\n",
    "#     \"\"\"\n",
    "#     event_times, predicted_scores, event_observed = _preprocess_scoring_data(event_times, predicted_scores, event_observed)\n",
    "#     num_correct, num_tied, num_pairs = _concordance_summary_statistics(event_times, predicted_scores, event_observed)\n",
    "\n",
    "#     return _concordance_ratio(num_correct, num_tied, num_pairs)\n",
    "\n",
    "\n",
    "# def _concordance_ratio(num_correct: int, num_tied: int, num_pairs: int) -> float:\n",
    "#     if num_pairs == 0:\n",
    "#         raise ZeroDivisionError(\"No admissable pairs in the dataset.\")\n",
    "#     return (num_correct + num_tied / 2) / num_pairs\n",
    "\n",
    "\n",
    "# def _concordance_summary_statistics(event_times, predicted_event_times, event_observed):  # pylint: disable=too-many-locals\n",
    "#     \"\"\"Find the concordance index in n * log(n) time.\n",
    "\n",
    "#     Assumes the data has been verified by lifelines.utils.concordance_index first.\n",
    "#     \"\"\"\n",
    "#     # Here's how this works.\n",
    "#     #\n",
    "#     # It would be pretty easy to do if we had no censored data and no ties. There, the basic idea\n",
    "#     # would be to iterate over the cases in order of their true event time (from least to greatest),\n",
    "#     # while keeping track of a pool of *predicted* event times for all cases previously seen (= all\n",
    "#     # cases that we know should be ranked lower than the case we're looking at currently).\n",
    "#     #\n",
    "#     # If the pool has O(log n) insert and O(log n) RANK (i.e., \"how many things in the pool have\n",
    "#     # value less than x\"), then the following algorithm is n log n:\n",
    "#     #\n",
    "#     # Sort the times and predictions by time, increasing\n",
    "#     # n_pairs, n_correct := 0\n",
    "#     # pool := {}\n",
    "#     # for each prediction p:\n",
    "#     #     n_pairs += len(pool)\n",
    "#     #     n_correct += rank(pool, p)\n",
    "#     #     add p to pool\n",
    "#     #\n",
    "#     # There are three complications: tied ground truth values, tied predictions, and censored\n",
    "#     # observations.\n",
    "#     #\n",
    "#     # - To handle tied true event times, we modify the inner loop to work in *batches* of observations\n",
    "#     # p_1, ..., p_n whose true event times are tied, and then add them all to the pool\n",
    "#     # simultaneously at the end.\n",
    "#     #\n",
    "#     # - To handle tied predictions, which should each count for 0.5, we switch to\n",
    "#     #     n_correct += min_rank(pool, p)\n",
    "#     #     n_tied += count(pool, p)\n",
    "#     #\n",
    "#     # - To handle censored observations, we handle each batch of tied, censored observations just\n",
    "#     # after the batch of observations that died at the same time (since those censored observations\n",
    "#     # are comparable all the observations that died at the same time or previously). However, we do\n",
    "#     # NOT add them to the pool at the end, because they are NOT comparable with any observations\n",
    "#     # that leave the study afterward--whether or not those observations get censored.\n",
    "#     if np.logical_not(event_observed).all():\n",
    "#         return (0, 0, 0)\n",
    "\n",
    "#     died_mask = event_observed.astype(bool)\n",
    "#     # TODO: is event_times already sorted? That would be nice...\n",
    "#     died_truth = event_times[died_mask]\n",
    "#     ix = np.argsort(died_truth)\n",
    "#     died_truth = died_truth[ix]\n",
    "#     died_pred = predicted_event_times[died_mask][ix]\n",
    "\n",
    "#     censored_truth = event_times[~died_mask]\n",
    "#     ix = np.argsort(censored_truth)\n",
    "#     censored_truth = censored_truth[ix]\n",
    "#     censored_pred = predicted_event_times[~died_mask][ix]\n",
    "\n",
    "#     censored_ix = 0\n",
    "#     died_ix = 0\n",
    "#     times_to_compare = _BTree(np.unique(died_pred))\n",
    "#     num_pairs = np.int64(0)\n",
    "#     num_correct = np.int64(0)\n",
    "#     num_tied = np.int64(0)\n",
    "\n",
    "#     # we iterate through cases sorted by exit time:\n",
    "#     # - First, all cases that died at time t0. We add these to the sortedlist of died times.\n",
    "#     # - Then, all cases that were censored at time t0. We DON'T add these since they are NOT\n",
    "#     #   comparable to subsequent elements.\n",
    "#     while True:\n",
    "#         has_more_censored = censored_ix < len(censored_truth)\n",
    "#         has_more_died = died_ix < len(died_truth)\n",
    "#         # Should we look at some censored indices next, or died indices?\n",
    "#         if has_more_censored and (not has_more_died or died_truth[died_ix] > censored_truth[censored_ix]):\n",
    "#             pairs, correct, tied, next_ix = _handle_pairs(censored_truth, censored_pred, censored_ix, times_to_compare)\n",
    "#             censored_ix = next_ix\n",
    "#         elif has_more_died and (not has_more_censored or died_truth[died_ix] <= censored_truth[censored_ix]):\n",
    "#             pairs, correct, tied, next_ix = _handle_pairs(died_truth, died_pred, died_ix, times_to_compare)\n",
    "#             for pred in died_pred[died_ix:next_ix]:\n",
    "#                 times_to_compare.insert(pred)\n",
    "#             died_ix = next_ix\n",
    "#         else:\n",
    "#             assert not (has_more_died or has_more_censored)\n",
    "#             break\n",
    "\n",
    "#         num_pairs += pairs\n",
    "#         num_correct += correct\n",
    "#         num_tied += tied\n",
    "\n",
    "#     return (num_correct, num_tied, num_pairs)\n",
    "\n",
    "\n",
    "# def _handle_pairs(truth, pred, first_ix, times_to_compare):\n",
    "#     \"\"\"\n",
    "#     Handle all pairs that exited at the same time as truth[first_ix].\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#       (pairs, correct, tied, next_ix)\n",
    "#       new_pairs: The number of new comparisons performed\n",
    "#       new_correct: The number of comparisons correctly predicted\n",
    "#       next_ix: The next index that needs to be handled\n",
    "#     \"\"\"\n",
    "#     next_ix = first_ix\n",
    "#     while next_ix < len(truth) and truth[next_ix] == truth[first_ix]:\n",
    "#         next_ix += 1\n",
    "#     pairs = len(times_to_compare) * (next_ix - first_ix)\n",
    "#     correct = np.int64(0)\n",
    "#     tied = np.int64(0)\n",
    "#     for i in range(first_ix, next_ix):\n",
    "#         rank, count = times_to_compare.rank(pred[i])\n",
    "#         correct += rank\n",
    "#         tied += count\n",
    "\n",
    "#     return (pairs, correct, tied, next_ix)\n",
    "\n",
    "\n",
    "# def _naive_concordance_summary_statistics(event_times, predicted_event_times, event_observed):\n",
    "#     \"\"\"\n",
    "#     Fallback, simpler method to compute concordance.\n",
    "\n",
    "#     \"\"\"\n",
    "\n",
    "#     def _valid_comparison(time_a, time_b, event_a, event_b):\n",
    "#         \"\"\"True if times can be compared.\"\"\"\n",
    "#         if time_a == time_b:\n",
    "#             # Ties are only informative if exactly one event happened\n",
    "#             return event_a != event_b\n",
    "#         if event_a and event_b:\n",
    "#             return True\n",
    "#         if event_a and time_a < time_b:\n",
    "#             return True\n",
    "#         if event_b and time_b < time_a:\n",
    "#             return True\n",
    "#         return False\n",
    "\n",
    "#     def _concordance_value(time_a, time_b, pred_a, pred_b, event_a, event_b):\n",
    "#         if pred_a == pred_b:\n",
    "#             # Same as random\n",
    "#             return (0, 1)\n",
    "#         if pred_a < pred_b:\n",
    "#             return (time_a < time_b) or (time_a == time_b and event_a and not event_b), 0\n",
    "#         # pred_a > pred_b\n",
    "#         return (time_a > time_b) or (time_a == time_b and not event_a and event_b), 0\n",
    "\n",
    "#     num_pairs = 0.0\n",
    "#     num_correct = 0.0\n",
    "#     num_tied = 0.0\n",
    "\n",
    "#     for a, time_a in enumerate(event_times):\n",
    "#         pred_a = predicted_event_times[a]\n",
    "#         event_a = event_observed[a]\n",
    "#         # Don't want to double count\n",
    "#         for b in range(a + 1, len(event_times)):\n",
    "#             time_b = event_times[b]\n",
    "#             pred_b = predicted_event_times[b]\n",
    "#             event_b = event_observed[b]\n",
    "\n",
    "#             if _valid_comparison(time_a, time_b, event_a, event_b):\n",
    "#                 num_pairs += 1.0\n",
    "#                 crct, ties = _concordance_value(time_a, time_b, pred_a, pred_b, event_a, event_b)\n",
    "#                 num_correct += crct\n",
    "#                 num_tied += ties\n",
    "\n",
    "#     return (num_correct, num_tied, num_pairs)\n",
    "\n",
    "\n",
    "# def naive_concordance_index(event_times, predicted_event_times, event_observed=None) -> float:\n",
    "#     event_times, predicted_event_times, event_observed = _preprocess_scoring_data(\n",
    "#         event_times, predicted_event_times, event_observed\n",
    "#     )\n",
    "#     return _concordance_ratio(*_naive_concordance_summary_statistics(event_times, predicted_event_times, event_observed))\n",
    "\n",
    "\n",
    "# def _preprocess_scoring_data(event_times, predicted_scores, event_observed):\n",
    "#     event_times = np.asarray(event_times, dtype=float)\n",
    "#     predicted_scores = np.asarray(predicted_scores, dtype=float)\n",
    "\n",
    "#     # Allow for (n, 1) or (1, n) arrays\n",
    "#     if event_times.ndim == 2 and (event_times.shape[0] == 1 or event_times.shape[1] == 1):\n",
    "#         # Flatten array\n",
    "#         event_times = event_times.ravel()\n",
    "#     # Allow for (n, 1) or (1, n) arrays\n",
    "#     if predicted_scores.ndim == 2 and (predicted_scores.shape[0] == 1 or predicted_scores.shape[1] == 1):\n",
    "#         # Flatten array\n",
    "#         predicted_scores = predicted_scores.ravel()\n",
    "\n",
    "#     if event_times.shape != predicted_scores.shape:\n",
    "#         raise ValueError(\"Event times and predictions must have the same shape\")\n",
    "#     if event_times.ndim != 1:\n",
    "#         raise ValueError(\"Event times can only be 1-dimensional: (n,)\")\n",
    "\n",
    "#     if event_observed is None:\n",
    "#         event_observed = np.ones(event_times.shape[0], dtype=float)\n",
    "#     else:\n",
    "#         event_observed = np.asarray(event_observed, dtype=float).ravel()\n",
    "#         if event_observed.shape != event_times.shape:\n",
    "#             raise ValueError(\"Observed events must be 1-dimensional of same length as event times\")\n",
    "\n",
    "#     # check for NaNs\n",
    "#     for a in [event_times, predicted_scores, event_observed]:\n",
    "#         if np.isnan(a).any():\n",
    "#             raise ValueError(\"NaNs detected in inputs, please correct or drop.\")\n",
    "\n",
    "#     return event_times, predicted_scores, event_observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "628cb5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- iPython Config --- ###\n",
    "from IPython import get_ipython\n",
    "if 'IPython.extensions.autoreload' not in get_ipython().extension_manager.loaded:\n",
    "    get_ipython().run_line_magic('load_ext', 'autoreload')\n",
    "else:\n",
    "    get_ipython().run_line_magic('reload_ext', 'autoreload')\n",
    "%autoreload 2\n",
    "### --- System and Path --- ###\n",
    "import os\n",
    "import sys\n",
    "repo_path = os.path.dirname(os.getcwd())\n",
    "if repo_path not in sys.path:\n",
    "    sys.path.append(repo_path)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from lifelines.utils import concordance_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb19353a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KERNEL_RUN_TYPE: local\n"
     ]
    }
   ],
   "source": [
    "# Configs\n",
    "SEED = 42\n",
    "kernel_run_type = \"kaggle\" if \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ else \"local\"\n",
    "print(f\"KERNEL_RUN_TYPE: {kernel_run_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efa56f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "if kernel_run_type==\"kaggle\":\n",
    "    df_train = pd.read_csv('/kaggle/input/equity-post-HCT-survival-predictions/train.csv')\n",
    "    df_test = pd.read_csv('/kaggle/input/equity-post-HCT-survival-predictions/test.csv')\n",
    "else:\n",
    "    # local\n",
    "    df_train = pd.read_csv(os.path.join(repo_path, 'data', 'raw', 'train.csv'))\n",
    "    df_test = pd.read_csv(os.path.join(repo_path, 'data', 'raw', 'test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f4e479",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_measurement_scales= {\n",
    "    # numerical\n",
    "    'age_at_hct': 'numerical',\n",
    "    'donor_age': 'numerical',\n",
    "    # cat-ordinal\n",
    "    'dri_score': 'ordinal',\n",
    "    'cyto_score': 'ordinal',\n",
    "    'cyto_score_detail': 'ordinal',\n",
    "    'conditioning_intensity': 'ordinal',\n",
    "    # cat-nominal\n",
    "    'hla_match_c_high': 'nominal',\n",
    "    'hla_high_res_8': 'nominal',\n",
    "    'hla_low_res_6': 'nominal',\n",
    "    'hla_high_res_6': 'nominal',\n",
    "    'hla_high_res_10': 'nominal',\n",
    "    'hla_match_dqb1_high': 'nominal',\n",
    "    'hla_nmdp_6': 'nominal',\n",
    "    'hla_match_c_low': 'nominal',\n",
    "    'hla_match_drb1_low': 'nominal',\n",
    "    'hla_match_dqb1_low': 'nominal',\n",
    "    'hla_match_a_high': 'nominal',\n",
    "    'hla_match_b_low': 'nominal',\n",
    "    'hla_match_a_low': 'nominal',\n",
    "    'hla_match_b_high': 'nominal',\n",
    "    'comorbidity_score': 'nominal',\n",
    "    'karnofsky_score': 'nominal',\n",
    "    'hla_low_res_8': 'nominal',\n",
    "    'hla_match_drb1_high': 'nominal',\n",
    "    'hla_low_res_10': 'nominal',\n",
    "    'ID': 'nominal',\n",
    "    'psych_disturb': 'nominal',\n",
    "    'diabetes': 'nominal',\n",
    "    'tbi_status': 'nominal',\n",
    "    'arrhythmia': 'nominal',\n",
    "    'graft_type': 'nominal',\n",
    "    'vent_hist': 'nominal',\n",
    "    'renal_issue': 'nominal',\n",
    "    'pulm_severe': 'nominal',\n",
    "    'prim_disease_hct': 'nominal',\n",
    "    'cmv_status': 'nominal',\n",
    "    'tce_imm_match': 'nominal',\n",
    "    'rituximab': 'nominal',\n",
    "    'prod_type': 'nominal',\n",
    "    'ethnicity': 'nominal',\n",
    "    'year_hct': 'nominal',\n",
    "    'obesity': 'nominal',\n",
    "    'mrd_hct': 'nominal',\n",
    "    'in_vivo_tcd': 'nominal',\n",
    "    'tce_match': 'nominal',\n",
    "    'hepatic_severe': 'nominal',\n",
    "    'prior_tumor': 'nominal',\n",
    "    'peptic_ulcer': 'nominal',\n",
    "    'gvhd_proph': 'nominal',\n",
    "    'rheum_issue': 'nominal',\n",
    "    'sex_match': 'nominal',\n",
    "    'race_group': 'nominal',\n",
    "    'hepatic_mild': 'nominal',\n",
    "    'tce_div_match': 'nominal',\n",
    "    'donor_related': 'nominal',\n",
    "    'melphalan_dose': 'nominal',\n",
    "    'cardiac': 'nominal',\n",
    "    'pulm_moderate': 'nominal',\n",
    "    # target\n",
    "    'efs': 'nominal', # binary target\n",
    "    'efs_time': 'numerical', # time\n",
    "}\n",
    "categorical_cols = [col for col, scale in cols_measurement_scales.items() if scale in ['nominal', 'ordinal']]\n",
    "nominal_cols = [col for col, scale in cols_measurement_scales.items() if scale in ['nominal']]\n",
    "ordinal_cols = [col for col, scale in cols_measurement_scales.items() if scale in ['ordinal']]\n",
    "numerical_cols = [col for col, scale in cols_measurement_scales.items() if scale in ['numerical']]\n",
    "\n",
    "# Check\n",
    "assert set(df_train.columns) == set(cols_measurement_scales.keys())\n",
    "assert len(cols_measurement_scales) == len(categorical_cols) + len(numerical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe397ca8",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b54be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns\n",
    "cols = ['ID']\n",
    "categorical_cols.remove('ID')\n",
    "nominal_cols.remove('ID')\n",
    "id_df_test = df_test['ID']  # For submission\n",
    "\n",
    "df_train.drop(cols, axis=1, inplace=True)\n",
    "df_test.drop(cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1b8f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "target = 'efs'\n",
    "target_time = 'efs_time'  # Survival time column\n",
    "categorical_cols.remove(target)\n",
    "nominal_cols.remove(target)\n",
    "numerical_cols.remove(target_time)\n",
    "# numerical_cols = [col for col in numerical_cols if col not in [target, target_time]]\n",
    "\n",
    "# train dataset\n",
    "X_train = df_train.drop([target, target_time], axis=1)\n",
    "y_train = df_train[target]\n",
    "efs_time = df_train[target_time]  # Extract survival times for C-index calculation\n",
    "# test dataset\n",
    "X_test = df_test  # No target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36500336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHotEncoding\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def one_hot_encoding(X_train, X_test, cat_cols=None):\n",
    "    # Identify categorical and numerical columns\n",
    "    num_cols = X_train.columns.difference(cat_cols)\n",
    "\n",
    "    # Apply OneHotEncoding\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "    X_train_cat = ohe.fit_transform(X_train[cat_cols])\n",
    "    X_test_cat = ohe.transform(X_test[cat_cols])\n",
    "\n",
    "    # Convert OHE to DataFrame and maintain column names\n",
    "    X_train_cat = pd.DataFrame(X_train_cat, columns=ohe.get_feature_names_out(), index=X_train.index)\n",
    "    X_test_cat = pd.DataFrame(X_test_cat, columns=ohe.get_feature_names_out(), index=X_test.index)\n",
    "\n",
    "    # Concatenate with Numerical columns\n",
    "    X_train_final = pd.concat([X_train[num_cols].reset_index(drop=True), X_train_cat.reset_index(drop=True)], axis=1)\n",
    "    X_test_final = pd.concat([X_test[num_cols].reset_index(drop=True), X_test_cat.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    # Ensure the same feature set between train and test\n",
    "    X_test_final = X_test_final.reindex(columns=X_train_final.columns, fill_value=0)\n",
    "\n",
    "    return X_train_final, X_test_final\n",
    "\n",
    "# X_train, X_test = one_hot_encoding(X_train.copy(), X_test.copy(), cat_cols=categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b58de3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "\n",
    "def encode_nominal_features(X_train, X_test, nominal_cols):\n",
    "    \"\"\"\n",
    "    Encodes nominal categorical features using LabelEncoder.\n",
    "\n",
    "    Parameters:\n",
    "    - X_train (pd.DataFrame): Training dataset.\n",
    "    - X_test (pd.DataFrame): Test dataset.\n",
    "    - categorical_cols (list): List of nominal categorical columns.\n",
    "\n",
    "    Returns:\n",
    "    - X_train_encoded (pd.DataFrame): Transformed training dataset with encoded nominal features.\n",
    "    - X_test_encoded (pd.DataFrame): Transformed test dataset with encoded nominal features.\n",
    "    \"\"\"\n",
    "    X_train_encoded, X_test_encoded = X_train.copy(), X_test.copy()\n",
    "\n",
    "    for col in nominal_cols:\n",
    "        le = LabelEncoder()\n",
    "        X_train_encoded[col] = le.fit_transform(X_train_encoded[col].astype(str))\n",
    "        X_test_encoded[col] = le.transform(X_test_encoded[col].astype(str))\n",
    "\n",
    "    return X_train_encoded, X_test_encoded\n",
    "\n",
    "def encode_ordinal_features(X_train, X_test, ordinal_cols):\n",
    "    \"\"\"\n",
    "    Encodes ordinal categorical features using OrdinalEncoder.\n",
    "    \"\"\"\n",
    "    X_train_encoded, X_test_encoded = X_train.copy(), X_test.copy()\n",
    "\n",
    "    for col in ordinal_cols:\n",
    "        oe = OrdinalEncoder()\n",
    "        X_train_encoded[col] = oe.fit_transform(X_train_encoded[[col]].astype(str))\n",
    "        X_test_encoded[col] = oe.transform(X_test_encoded[[col]].astype(str))\n",
    "\n",
    "    return X_train_encoded, X_test_encoded\n",
    "\n",
    "# X_train, X_test = encode_nominal_features(X_train, X_test, nominal_cols)\n",
    "# X_train, X_test = encode_ordinal_features(X_train, X_test, ordinal_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70ac3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fillna with 'UNK'\n",
    "X_train[categorical_cols] = X_train[categorical_cols].fillna('UNK').astype(str)\n",
    "X_test[categorical_cols] = X_test[categorical_cols].fillna('UNK').astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7acdd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def scale_to_standard(X_train, X_test, num_cols=None):\n",
    "    \"\"\"\n",
    "    Scales numerical features to standard normal distribution (mean=0, std=1).\n",
    "    \"\"\"\n",
    "\n",
    "    # Apply Standard Scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train[num_cols])\n",
    "    X_test_scaled = scaler.transform(X_test[num_cols])\n",
    "\n",
    "    # Convert back to DataFrame\n",
    "    X_train_scaled = pd.DataFrame(X_train_scaled, columns=num_cols, index=X_train.index)\n",
    "    X_test_scaled = pd.DataFrame(X_test_scaled, columns=num_cols, index=X_test.index)\n",
    "\n",
    "    # Replace original numerical features with scaled ones\n",
    "    X_train_final = X_train.copy()\n",
    "    X_test_final = X_test.copy()\n",
    "    X_train_final[num_cols] = X_train_scaled\n",
    "    X_test_final[num_cols] = X_test_scaled\n",
    "\n",
    "    return X_train_final, X_test_final\n",
    "\n",
    "# Apply the transformation\n",
    "X_train, X_test = scale_to_standard(X_train.copy(), X_test.copy(), num_cols=numerical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6231ac",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5231361",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T17:18:29.992554Z",
     "iopub.status.busy": "2025-02-02T17:18:29.992068Z",
     "iopub.status.idle": "2025-02-02T17:22:30.524401Z",
     "shell.execute_reply": "2025-02-02T17:22:30.523306Z"
    },
    "papermill": {
     "duration": 240.537606,
     "end_time": "2025-02-02T17:22:30.526545",
     "exception": false,
     "start_time": "2025-02-02T17:18:29.988939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-12 00:24:54,280] A new study created in memory with name: no-name-2ff7cda8-6496-46b3-a668-753ef3ef86a8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting cross-validation for trial: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6720339\ttotal: 88.4ms\tremaining: 14m 44s\n",
      "2000:\tlearn: 0.3360918\ttotal: 58.8s\tremaining: 3m 54s\n",
      "4000:\tlearn: 0.2114758\ttotal: 2m 2s\tremaining: 3m 3s\n",
      "6000:\tlearn: 0.1377677\ttotal: 3m 14s\tremaining: 2m 9s\n",
      "8000:\tlearn: 0.0926149\ttotal: 4m 31s\tremaining: 1m 7s\n",
      "9999:\tlearn: 0.0635635\ttotal: 5m 39s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [05:40<11:21, 340.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1, Fold 1: C-Index=0.6435378623189107\n",
      "0:\tlearn: 0.6733891\ttotal: 30.1ms\tremaining: 5m 1s\n",
      "2000:\tlearn: 0.3424876\ttotal: 1m 7s\tremaining: 4m 27s\n",
      "4000:\tlearn: 0.2199805\ttotal: 2m 14s\tremaining: 3m 21s\n",
      "6000:\tlearn: 0.1422296\ttotal: 3m 25s\tremaining: 2m 16s\n",
      "8000:\tlearn: 0.0966364\ttotal: 4m 35s\tremaining: 1m 8s\n",
      "9999:\tlearn: 0.0684912\ttotal: 5m 43s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [11:26<05:43, 343.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1, Fold 2: C-Index=0.6445330360068166\n",
      "0:\tlearn: 0.6729078\ttotal: 36ms\tremaining: 6m\n",
      "2000:\tlearn: 0.3396890\ttotal: 1m 9s\tremaining: 4m 36s\n",
      "4000:\tlearn: 0.2154442\ttotal: 2m 19s\tremaining: 3m 28s\n",
      "6000:\tlearn: 0.1393765\ttotal: 3m 28s\tremaining: 2m 18s\n",
      "8000:\tlearn: 0.0947088\ttotal: 4m 35s\tremaining: 1m 8s\n",
      "9999:\tlearn: 0.0658231\ttotal: 5m 44s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [17:12<00:00, 344.19s/it]\n",
      "[I 2025-02-12 00:42:06,949] Trial 0 finished with value: 0.6430633467238634 and parameters: {'learning_rate': 0.1715428040856273, 'depth': 5, 'l2_leaf_reg': 2.2916046279316142}. Best is trial 0 with value: 0.6430633467238634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1, Fold 3: C-Index=0.641119141845863\n",
      "Starting cross-validation for trial: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6924415\ttotal: 26.7ms\tremaining: 4m 27s\n",
      "2000:\tlearn: 0.5728806\ttotal: 1m 5s\tremaining: 4m 21s\n",
      "4000:\tlearn: 0.5504059\ttotal: 2m 14s\tremaining: 3m 21s\n",
      "6000:\tlearn: 0.5358818\ttotal: 3m 33s\tremaining: 2m 22s\n",
      "8000:\tlearn: 0.5240728\ttotal: 4m 48s\tremaining: 1m 11s\n",
      "9999:\tlearn: 0.5134303\ttotal: 6m 1s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [06:03<12:07, 363.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2, Fold 1: C-Index=0.6628514698591081\n",
      "0:\tlearn: 0.6924872\ttotal: 30.7ms\tremaining: 5m 6s\n",
      "2000:\tlearn: 0.5777623\ttotal: 1m 9s\tremaining: 4m 35s\n",
      "4000:\tlearn: 0.5563433\ttotal: 2m 25s\tremaining: 3m 38s\n",
      "6000:\tlearn: 0.5416587\ttotal: 3m 36s\tremaining: 2m 24s\n",
      "8000:\tlearn: 0.5296001\ttotal: 4m 48s\tremaining: 1m 12s\n",
      "9999:\tlearn: 0.5188198\ttotal: 6m\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [12:06<06:02, 362.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2, Fold 2: C-Index=0.6675837096698001\n",
      "0:\tlearn: 0.6924708\ttotal: 35.9ms\tremaining: 5m 59s\n",
      "2000:\tlearn: 0.5766392\ttotal: 1m 8s\tremaining: 4m 32s\n",
      "4000:\tlearn: 0.5551891\ttotal: 2m 22s\tremaining: 3m 33s\n",
      "6000:\tlearn: 0.5407287\ttotal: 3m 35s\tremaining: 2m 23s\n",
      "8000:\tlearn: 0.5287946\ttotal: 4m 50s\tremaining: 1m 12s\n",
      "9999:\tlearn: 0.5180320\ttotal: 6m\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [18:07<00:00, 362.55s/it]\n",
      "[I 2025-02-12 01:00:14,640] Trial 1 finished with value: 0.6649591607683218 and parameters: {'learning_rate': 0.005191012766953341, 'depth': 5, 'l2_leaf_reg': 1.4189986059462765}. Best is trial 1 with value: 0.6649591607683218.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2, Fold 3: C-Index=0.6644423027760574\n",
      "Starting cross-validation for trial: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6840583\ttotal: 108ms\tremaining: 18m 2s\n",
      "2000:\tlearn: 0.2184402\ttotal: 2m 28s\tremaining: 9m 54s\n",
      "4000:\tlearn: 0.0989150\ttotal: 5m 2s\tremaining: 7m 32s\n",
      "6000:\tlearn: 0.0534036\ttotal: 7m 29s\tremaining: 4m 59s\n",
      "8000:\tlearn: 0.0354443\ttotal: 10m 15s\tremaining: 2m 33s\n",
      "9999:\tlearn: 0.0256843\ttotal: 12m 54s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [12:57<25:54, 777.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3, Fold 1: C-Index=0.6522418579838261\n",
      "0:\tlearn: 0.6840772\ttotal: 77ms\tremaining: 12m 50s\n",
      "2000:\tlearn: 0.2298260\ttotal: 2m 28s\tremaining: 9m 53s\n",
      "4000:\tlearn: 0.1070146\ttotal: 5m 12s\tremaining: 7m 48s\n",
      "6000:\tlearn: 0.0590118\ttotal: 8m 21s\tremaining: 5m 33s\n",
      "8000:\tlearn: 0.0381974\ttotal: 10m 57s\tremaining: 2m 44s\n",
      "9999:\tlearn: 0.0279578\ttotal: 13m 24s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [26:23<13:14, 794.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3, Fold 2: C-Index=0.6537564179028237\n",
      "0:\tlearn: 0.6840529\ttotal: 85.7ms\tremaining: 14m 16s\n",
      "2000:\tlearn: 0.2363711\ttotal: 2m 26s\tremaining: 9m 44s\n",
      "4000:\tlearn: 0.1098055\ttotal: 5m 2s\tremaining: 7m 33s\n",
      "6000:\tlearn: 0.0595835\ttotal: 7m 27s\tremaining: 4m 58s\n",
      "8000:\tlearn: 0.0379804\ttotal: 9m 57s\tremaining: 2m 29s\n",
      "9999:\tlearn: 0.0272964\ttotal: 12m 21s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [38:47<00:00, 775.68s/it]\n",
      "[I 2025-02-12 01:39:01,750] Trial 2 finished with value: 0.651713800359857 and parameters: {'learning_rate': 0.06581906203131095, 'depth': 8, 'l2_leaf_reg': 4.7648848160381405}. Best is trial 1 with value: 0.6649591607683218.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3, Fold 3: C-Index=0.6491431251929214\n",
      "Number of finished trials: 3\n",
      "Best trial:\n",
      "  Best C-index: 0.6649591607683218\n",
      "  Params: \n",
      "    learning_rate: 0.005191012766953341\n",
      "    depth: 5\n",
      "    l2_leaf_reg: 1.4189986059462765\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Compute class weights to handle imbalanced target\n",
    "def compute_scale_pos_weight(y_train):\n",
    "    unique_classes = np.unique(y_train)\n",
    "    if len(unique_classes) < 2:\n",
    "        return 1  # Avoid issues if only one class is present (shouldn't happen in normal training)\n",
    "\n",
    "    class_weights = compute_class_weight(\"balanced\", classes=unique_classes, y=y_train)\n",
    "    neg_class_weight = class_weights[0]  # Weight for class 0\n",
    "    pos_class_weight = class_weights[1]  # Weight for class 1\n",
    "\n",
    "    return (\n",
    "        pos_class_weight / neg_class_weight\n",
    "    )  # Scale positive class relative to negative\n",
    "scale_pos_weight = compute_scale_pos_weight(y_train)\n",
    "\n",
    "# Parameters\n",
    "DEFAULT_ITERATIONS = 10_000\n",
    "VERBOSE = 2_000\n",
    "train_dir = os.path.join(repo_path, \"models\", \"catboost_info\")\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "\n",
    "base_params = {\n",
    "    \"loss_function\": \"Logloss\",\n",
    "    \"cat_features\": categorical_cols,\n",
    "    \"scale_pos_weight\": scale_pos_weight,\n",
    "    \"train_dir\": train_dir,\n",
    "    \"iterations\": DEFAULT_ITERATIONS,\n",
    "    \"verbose\": VERBOSE,\n",
    "    \"random_state\": SEED,\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Optuna optimization using C-index as the evaluation criterion.\n",
    "    \"\"\"\n",
    "\n",
    "    learnable_params = {\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 5e-3, 2e-1),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 5, 8),\n",
    "        \"l2_leaf_reg\": trial.suggest_uniform(\"l2_leaf_reg\", 1, 5),\n",
    "    }\n",
    "\n",
    "    params = {**base_params, **learnable_params}\n",
    "    model = CatBoostClassifier(**params)\n",
    "\n",
    "    cv_folds = 3\n",
    "    cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=SEED)\n",
    "    fold_scores = []\n",
    "    print(f\"Starting cross-validation for trial: {trial.number+1}\")\n",
    "    for fold, (train_idx, val_idx) in tqdm(enumerate(cv.split(X_train, y_train), 1), total=cv_folds):\n",
    "        # print(f\"Trial {trial.number}, Fold {fold}: Training the model...\")\n",
    "\n",
    "        x_tr, x_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        efs_time_val = efs_time.iloc[val_idx]  # Get survival times for validation\n",
    "\n",
    "        # Train model\n",
    "        model.fit(x_tr, y_tr)\n",
    "\n",
    "        # Predict risk scores (probabilities)\n",
    "        y_pred_proba = model.predict_proba(x_val)[:, 1]  # Higher values mean higher risk\n",
    "\n",
    "        # Compute Concordance Index\n",
    "        c_index = concordance_index(\n",
    "            efs_time_val, -y_pred_proba, y_val\n",
    "        )  # Negative for risk interpretation\n",
    "        print(f\"Trial {trial.number+1}, Fold {fold}: C-Index={c_index}\")\n",
    "        fold_scores.append(c_index)\n",
    "\n",
    "    return np.mean(fold_scores)  # Maximizing mean C-index\n",
    "\n",
    "# Print results\n",
    "def print_optuna_results(study):\n",
    "    print(\"Number of finished trials:\", len(study.trials))\n",
    "    print(\"Best trial:\")\n",
    "    trial_ = study.best_trial\n",
    "    print(\"  Best C-index:\", trial_.value)\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial_.params.items():\n",
    "        print(f\"    {key}: {value}\")\n",
    "\n",
    "\n",
    "# Running the optimization...\n",
    "n_trials = 3\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=n_trials, show_progress_bar=False, timeout=None)\n",
    "print_optuna_results(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f42d4e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6924921\ttotal: 42.6ms\tremaining: 7m 5s\n",
      "2000:\tlearn: 0.5796216\ttotal: 1m 31s\tremaining: 6m 6s\n",
      "4000:\tlearn: 0.5616590\ttotal: 3m 5s\tremaining: 4m 38s\n",
      "6000:\tlearn: 0.5503534\ttotal: 4m 40s\tremaining: 3m 6s\n",
      "8000:\tlearn: 0.5412890\ttotal: 6m 14s\tremaining: 1m 33s\n",
      "9999:\tlearn: 0.5332033\ttotal: 7m 49s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/Users/pupipatsingkhorn/Developer/repositories/CIBMTR-equity-post-HCT-survival-predictions/models/20250212-0146-model.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the final model with best parameters\n",
    "best_learnable_params = study.best_params\n",
    "params = {**base_params, **best_learnable_params}\n",
    "final_model = CatBoostClassifier(**params)\n",
    "\n",
    "# Fitting final model...\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Save the model\n",
    "if kernel_run_type==\"kaggle\":\n",
    "    filepath = ''\n",
    "else:\n",
    "    time_now = time.strftime(\"%Y%m%d-%H%M\")\n",
    "    filepath = os.path.join(repo_path, \"models\", f\"{time_now}-model.pkl\")\n",
    "joblib.dump(final_model, filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96ed8fa",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d2581ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load final model\n",
    "if kernel_run_type==\"kaggle\":\n",
    "    # change here\n",
    "    filepath = '/kaggle/input/20250204-2157-model.pkl/scikitlearn/default/1/20250204-2157-model.pkl'\n",
    "else: # local\n",
    "    model_name = \"20250204-2157-model.pkl\" # change here\n",
    "    filepath = os.path.join(repo_path, \"models\", model_name)\n",
    "final_model = joblib.load(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54fa4534",
   "metadata": {},
   "outputs": [
    {
     "ename": "CatBoostError",
     "evalue": "Bad value for num_feature[non_default_doc_idx=0,feature_idx=0]=\"N/A - non-malignant indication\": Cannot convert 'b'N/A - non-malignant indication'' to float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m_catboost.pyx:2547\u001b[0m, in \u001b[0;36m_catboost.get_float_feature\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:1226\u001b[0m, in \u001b[0;36m_catboost._FloatOrNan\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:1021\u001b[0m, in \u001b[0;36m_catboost._FloatOrNanFromString\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert 'b'N/A - non-malignant indication'' to float",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m y_pred_proba \u001b[38;5;241m=\u001b[39m final_model\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)[:, \u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Probability of event occurring\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Save submission\u001b[39;00m\n\u001b[1;32m      5\u001b[0m df_submission \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m: id_df_test, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m'\u001b[39m: y_pred_proba})\n",
      "File \u001b[0;32m~/miniconda3/envs/datascience/lib/python3.11/site-packages/catboost/core.py:5351\u001b[0m, in \u001b[0;36mCatBoostClassifier.predict_proba\u001b[0;34m(self, X, ntree_start, ntree_end, thread_count, verbose, task_type)\u001b[0m\n\u001b[1;32m   5309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, ntree_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, ntree_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, thread_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, task_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCPU\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   5310\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5311\u001b[0m \u001b[38;5;124;03m    Predict class probability with X.\u001b[39;00m\n\u001b[1;32m   5312\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5349\u001b[0m \u001b[38;5;124;03m            with probability for every class for each object.\u001b[39;00m\n\u001b[1;32m   5350\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict(X, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProbability\u001b[39m\u001b[38;5;124m'\u001b[39m, ntree_start, ntree_end, thread_count, verbose, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredict_proba\u001b[39m\u001b[38;5;124m'\u001b[39m, task_type)\n",
      "File \u001b[0;32m~/miniconda3/envs/datascience/lib/python3.11/site-packages/catboost/core.py:2620\u001b[0m, in \u001b[0;36mCatBoost._predict\u001b[0;34m(self, data, prediction_type, ntree_start, ntree_end, thread_count, verbose, parent_method_name, task_type)\u001b[0m\n\u001b[1;32m   2618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2619\u001b[0m     verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 2620\u001b[0m data, data_is_single_object \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_predict_input_data(data, parent_method_name, thread_count)\n\u001b[1;32m   2621\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_prediction_type(prediction_type)\n\u001b[1;32m   2623\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_predict(data, prediction_type, ntree_start, ntree_end, thread_count, verbose, task_type)\n",
      "File \u001b[0;32m~/miniconda3/envs/datascience/lib/python3.11/site-packages/catboost/core.py:2600\u001b[0m, in \u001b[0;36mCatBoost._process_predict_input_data\u001b[0;34m(self, data, parent_method_name, thread_count, label)\u001b[0m\n\u001b[1;32m   2598\u001b[0m is_single_object \u001b[38;5;241m=\u001b[39m _is_data_single_object(data)\n\u001b[1;32m   2599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Pool):\n\u001b[0;32m-> 2600\u001b[0m     data \u001b[38;5;241m=\u001b[39m Pool(\n\u001b[1;32m   2601\u001b[0m         data\u001b[38;5;241m=\u001b[39m[data] \u001b[38;5;28;01mif\u001b[39;00m is_single_object \u001b[38;5;28;01melse\u001b[39;00m data,\n\u001b[1;32m   2602\u001b[0m         label\u001b[38;5;241m=\u001b[39mlabel,\n\u001b[1;32m   2603\u001b[0m         cat_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_cat_feature_indices() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, FeaturesData) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2604\u001b[0m         text_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_text_feature_indices() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, FeaturesData) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2605\u001b[0m         embedding_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_embedding_feature_indices() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, FeaturesData) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2606\u001b[0m         thread_count\u001b[38;5;241m=\u001b[39mthread_count\n\u001b[1;32m   2607\u001b[0m     )\n\u001b[1;32m   2608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data, is_single_object\n",
      "File \u001b[0;32m~/miniconda3/envs/datascience/lib/python3.11/site-packages/catboost/core.py:855\u001b[0m, in \u001b[0;36mPool.__init__\u001b[0;34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, column_description, pairs, graph, delimiter, has_header, ignore_csv_quoting, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count, log_cout, log_cerr, data_can_be_none)\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(feature_names, PATH_TYPES):\n\u001b[1;32m    850\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError(\n\u001b[1;32m    851\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_names must be None or have non-string type when the pool is created from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    852\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython objects.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    853\u001b[0m             )\n\u001b[0;32m--> 855\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, graph, weight,\n\u001b[1;32m    856\u001b[0m                    group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\n\u001b[1;32m    857\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data_can_be_none:\n\u001b[1;32m    858\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m parameter can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/datascience/lib/python3.11/site-packages/catboost/core.py:1491\u001b[0m, in \u001b[0;36mPool._init\u001b[0;34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, graph, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\u001b[0m\n\u001b[1;32m   1489\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feature_tags \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1490\u001b[0m     feature_tags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_transform_tags(feature_tags, feature_names)\n\u001b[0;32m-> 1491\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, graph, weight,\n\u001b[1;32m   1492\u001b[0m                 group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\n",
      "File \u001b[0;32m_catboost.pyx:4339\u001b[0m, in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:4391\u001b[0m, in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:4200\u001b[0m, in \u001b[0;36m_catboost._PoolBase._init_features_order_layout_pool\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:3127\u001b[0m, in \u001b[0;36m_catboost._set_features_order_data_pd_data_frame\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:2591\u001b[0m, in \u001b[0;36m_catboost.create_num_factor_data\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:2549\u001b[0m, in \u001b[0;36m_catboost.get_float_feature\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCatBoostError\u001b[0m: Bad value for num_feature[non_default_doc_idx=0,feature_idx=0]=\"N/A - non-malignant indication\": Cannot convert 'b'N/A - non-malignant indication'' to float"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "y_pred_proba = final_model.predict_proba(X_test)[:, 1]  # Probability of event occurring\n",
    "\n",
    "# Save submission\n",
    "df_submission = pd.DataFrame({'ID': id_df_test, 'prediction': y_pred_proba})\n",
    "if kernel_run_type==\"kaggle\":\n",
    "    df_submission.to_csv('submission.csv', index=False)\n",
    "else:\n",
    "    # local\n",
    "    # main file:\n",
    "    filepath = os.path.join(repo_path, 'data', 'submission', 'submission.csv')\n",
    "    df_submission.to_csv(filepath, index=False)\n",
    "    # archive file:\n",
    "    time_now = time.strftime(\"%Y%m%d-%H%M\")\n",
    "    filepath = os.path.join(repo_path, 'data', 'submission', 'archive', f'{time_now}-submission.csv')\n",
    "    df_submission.to_csv(filepath, index=False)\n",
    "print(f\"Submission saved on {kernel_run_type} successfully.\")\n",
    "\n",
    "df_submission"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 10381525,
     "sourceId": 70942,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 244.250158,
   "end_time": "2025-02-02T17:22:31.352616",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-02T17:18:27.102458",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1256232a33fa4888a7f96230439e2c76": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2f70d247e98442a0bff0a9f4e651031a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f456bd28218b48ca8a0abb1a163306e5",
        "IPY_MODEL_348fb90e32534922ae866a89c1535cea",
        "IPY_MODEL_99c2aa12d63040d7b60448dc449b7cc6"
       ],
       "layout": "IPY_MODEL_a372d2ca55da443ab6e8aae9f29934f1",
       "tabbable": null,
       "tooltip": null
      }
     },
     "348fb90e32534922ae866a89c1535cea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_548558cadb21425fa3fef9305a927579",
       "max": 7,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3543bcb390944447adc4386a7e5ba51f",
       "tabbable": null,
       "tooltip": null,
       "value": 7
      }
     },
     "3543bcb390944447adc4386a7e5ba51f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3ca0c22c7fb941f783d6b92de7b73668": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "548558cadb21425fa3fef9305a927579": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "99c2aa12d63040d7b60448dc449b7cc6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1256232a33fa4888a7f96230439e2c76",
       "placeholder": "​",
       "style": "IPY_MODEL_bfe67bb1596d48cabb27d337b9657ef5",
       "tabbable": null,
       "tooltip": null,
       "value": " 7/7 [03:49&lt;00:00, 51.89s/it]"
      }
     },
     "9bd3cf423c1f4d308c5a9c8d7cb2de68": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a372d2ca55da443ab6e8aae9f29934f1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bfe67bb1596d48cabb27d337b9657ef5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f456bd28218b48ca8a0abb1a163306e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9bd3cf423c1f4d308c5a9c8d7cb2de68",
       "placeholder": "​",
       "style": "IPY_MODEL_3ca0c22c7fb941f783d6b92de7b73668",
       "tabbable": null,
       "tooltip": null,
       "value": "Best trial: 2. Best value: 0.662272: 100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
