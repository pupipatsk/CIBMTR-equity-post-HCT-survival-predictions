{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d734aef9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T17:18:29.952444Z",
     "iopub.status.busy": "2025-02-02T17:18:29.952010Z",
     "iopub.status.idle": "2025-02-02T17:18:29.984227Z",
     "shell.execute_reply": "2025-02-02T17:18:29.983025Z"
    },
    "papermill": {
     "duration": 0.038567,
     "end_time": "2025-02-02T17:18:29.986287",
     "exception": false,
     "start_time": "2025-02-02T17:18:29.947720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ### Implementation of 'from lifelines.utils import concordance_index'\n",
    "# # because of no internet access(!pip install lifelines) when inferencing with kaggle\n",
    "# # src: https://github.com/CamDavidsonPilon/lifelines/blob/47afb1c1a272b0f03e0c8ca00e63df27eb2a0560/lifelines/utils/concordance.py\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# class _BTree:\n",
    "\n",
    "#     \"\"\"A simple balanced binary order statistic tree to help compute the concordance.\n",
    "\n",
    "#     When computing the concordance, we know all the values the tree will ever contain. That\n",
    "#     condition simplifies this tree a lot. It means that instead of crazy AVL/red-black shenanigans\n",
    "#     we can simply do the following:\n",
    "\n",
    "#     - Store the final tree in flattened form in an array (so node i's children are 2i+1, 2i+2)\n",
    "#     - Additionally, store the current size of each subtree in another array with the same indices\n",
    "#     - To insert a value, just find its index, increment the size of the subtree at that index and\n",
    "#       propagate\n",
    "#     - To get the rank of an element, you add up a bunch of subtree counts\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, values):\n",
    "#         \"\"\"\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         values: list\n",
    "#             List of sorted (ascending), unique values that will be inserted.\n",
    "#         \"\"\"\n",
    "#         self._tree = self._treeify(values)\n",
    "#         self._counts = np.zeros_like(self._tree, dtype=int)\n",
    "\n",
    "#     @staticmethod\n",
    "#     def _treeify(values):\n",
    "#         \"\"\"Convert the np.ndarray `values` into a complete balanced tree.\n",
    "\n",
    "#         Assumes `values` is sorted ascending. Returns a list `t` of the same length in which t[i] >\n",
    "#         t[2i+1] and t[i] < t[2i+2] for all i.\"\"\"\n",
    "#         if len(values) == 1:  # this case causes problems later\n",
    "#             return values\n",
    "#         tree = np.empty_like(values)\n",
    "#         # Tree indices work as follows:\n",
    "#         # 0 is the root\n",
    "#         # 2n+1 is the left child of n\n",
    "#         # 2n+2 is the right child of n\n",
    "#         # So we now rearrange `values` into that format...\n",
    "\n",
    "#         # The first step is to remove the bottom row of leaves, which might not be exactly full\n",
    "#         last_full_row = int(np.log2(len(values) + 1) - 1)\n",
    "#         len_ragged_row = len(values) - (2 ** (last_full_row + 1) - 1)\n",
    "#         if len_ragged_row > 0:\n",
    "#             bottom_row_ix = np.s_[: 2 * len_ragged_row : 2]\n",
    "#             tree[-len_ragged_row:] = values[bottom_row_ix]\n",
    "#             values = np.delete(values, bottom_row_ix)\n",
    "\n",
    "#         # Now `values` is length 2**n - 1, so can be packed efficiently into a tree\n",
    "#         # Last row of nodes is indices 0, 2, ..., 2**n - 2\n",
    "#         # Second-last row is indices 1, 5, ..., 2**n - 3\n",
    "#         # nth-last row is indices (2**n - 1)::(2**(n+1))\n",
    "#         values_start = 0\n",
    "#         values_space = 2\n",
    "#         values_len = 2 ** last_full_row\n",
    "#         while values_start < len(values):\n",
    "#             tree[values_len - 1 : 2 * values_len - 1] = values[values_start::values_space]\n",
    "#             values_start += int(values_space / 2)\n",
    "#             values_space *= 2\n",
    "#             values_len = int(values_len / 2)\n",
    "#         return tree\n",
    "\n",
    "#     def insert(self, value):\n",
    "#         \"\"\"Insert an occurrence of `value` into the btree.\"\"\"\n",
    "#         i = 0\n",
    "#         n = len(self._tree)\n",
    "#         while i < n:\n",
    "#             cur = self._tree[i]\n",
    "#             self._counts[i] += 1\n",
    "#             if value < cur:\n",
    "#                 i = 2 * i + 1\n",
    "#             elif value > cur:\n",
    "#                 i = 2 * i + 2\n",
    "#             else:\n",
    "#                 return\n",
    "#         raise ValueError(\"Value %s not contained in tree.\" \"Also, the counts are now messed up.\" % value)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return self._counts[0]\n",
    "\n",
    "#     def rank(self, value):\n",
    "#         \"\"\"Returns the rank and count of the value in the btree.\"\"\"\n",
    "#         i = 0\n",
    "#         n = len(self._tree)\n",
    "#         rank = 0\n",
    "#         count = 0\n",
    "#         while i < n:\n",
    "#             cur = self._tree[i]\n",
    "#             if value < cur:\n",
    "#                 i = 2 * i + 1\n",
    "#                 continue\n",
    "#             elif value > cur:\n",
    "#                 rank += self._counts[i]\n",
    "#                 # subtract off the right tree if exists\n",
    "#                 nexti = 2 * i + 2\n",
    "#                 if nexti < n:\n",
    "#                     rank -= self._counts[nexti]\n",
    "#                     i = nexti\n",
    "#                     continue\n",
    "#                 else:\n",
    "#                     return (rank, count)\n",
    "#             else:  # value == cur\n",
    "#                 count = self._counts[i]\n",
    "#                 lefti = 2 * i + 1\n",
    "#                 if lefti < n:\n",
    "#                     nleft = self._counts[lefti]\n",
    "#                     count -= nleft\n",
    "#                     rank += nleft\n",
    "#                     righti = lefti + 1\n",
    "#                     if righti < n:\n",
    "#                         count -= self._counts[righti]\n",
    "#                 return (rank, count)\n",
    "#         return (rank, count)\n",
    "\n",
    "# # -*- coding: utf-8 -*-\n",
    "\n",
    "# import numpy as np\n",
    "# # from lifelines.utils.btree import _BTree\n",
    "\n",
    "\n",
    "# def somers_d(event_times, x, event_observed=None) -> float:\n",
    "#     \"\"\"\n",
    "#     A measure of rank association between [-1, 1] between a censored variable, event_times,\n",
    "#     and another (uncensored) variable, x. -1 is strong anti-correlation, 1 is strong correlation.\n",
    "\n",
    "\n",
    "#     event_times: iterable\n",
    "#          a length-n iterable of observed survival times.\n",
    "#     x: iterable\n",
    "#         a length-n iterable to compare against\n",
    "#     event_observed: iterable, optional\n",
    "#         a length-n iterable censoring flags, 1 if observed, 0 if not. Default None assumes all observed.\n",
    "\n",
    "\n",
    "#     Examples\n",
    "#     --------\n",
    "#     .. code:: python\n",
    "#         from lifelines.datasets import load_rossi\n",
    "#         from lifelines.utils\n",
    "\n",
    "#         T, E = df['week'], df['arrest']\n",
    "#         x = df['age']\n",
    "#         somers_d(T, x, E)\n",
    "\n",
    "\n",
    "#     \"\"\"\n",
    "#     return 2 * concordance_index(event_times, x, event_observed) - 1\n",
    "\n",
    "\n",
    "# def concordance_index(event_times, predicted_scores, event_observed=None) -> float:\n",
    "#     \"\"\"\n",
    "#     Calculates the concordance index (C-index) between a series\n",
    "#     of event times and a predicted score. The first is the real survival times from\n",
    "#     the observational data, and the other is the predicted score from a model of some kind.\n",
    "\n",
    "#     The c-index is the average of how often a model says X is greater than Y when, in the observed\n",
    "#     data, X is indeed greater than Y. The c-index also handles how to handle censored values\n",
    "#     (obviously, if Y is censored, it's hard to know if X is truly greater than Y).\n",
    "\n",
    "\n",
    "#     The concordance index is a value between 0 and 1 where:\n",
    "\n",
    "#     - 0.5 is the expected result from random predictions,\n",
    "#     - 1.0 is perfect concordance and,\n",
    "#     - 0.0 is perfect anti-concordance (multiply predictions with -1 to get 1.0)\n",
    "\n",
    "#     The calculation internally done is\n",
    "\n",
    "#     >>> (pairs_correct + 0.5 * pairs_tied) / admissable_pairs\n",
    "\n",
    "#     where ``pairs_correct`` is the number of pairs s.t. if ``t_x > t_y``, then ``s_x > s_y``, pairs,\n",
    "#     ``pairs_tied`` is the number of pairs where ``s_x = s_y``, and ``admissable_pairs`` is all possible pairs. The subtleties\n",
    "#     are in how censored observation are handled (ex: not all pairs can be evaluated due to censoring).\n",
    "\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     event_times: iterable\n",
    "#          a length-n iterable of observed survival times.\n",
    "#     predicted_scores: iterable\n",
    "#         a length-n iterable of predicted scores - these could be survival times, or hazards, etc. See https://stats.stackexchange.com/questions/352183/use-median-survival-time-to-calculate-cph-c-statistic/352435#352435\n",
    "#     event_observed: iterable, optional\n",
    "#         a length-n iterable censoring flags, 1 if observed, 0 if not. Default None assumes all observed.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     c-index: float\n",
    "#       a value between 0 and 1.\n",
    "\n",
    "#     References\n",
    "#     -----------\n",
    "#     Harrell FE, Lee KL, Mark DB. Multivariable prognostic models: issues in\n",
    "#     developing models, evaluating assumptions and adequacy, and measuring and\n",
    "#     reducing errors. Statistics in Medicine 1996;15(4):361-87.\n",
    "\n",
    "#     Examples\n",
    "#     --------\n",
    "#     .. code:: python\n",
    "\n",
    "#         from lifelines.utils import concordance_index\n",
    "#         cph = CoxPHFitter().fit(df, 'T', 'E')\n",
    "#         concordance_index(df['T'], -cph.predict_partial_hazard(df), df['E'])\n",
    "\n",
    "#     \"\"\"\n",
    "#     event_times, predicted_scores, event_observed = _preprocess_scoring_data(event_times, predicted_scores, event_observed)\n",
    "#     num_correct, num_tied, num_pairs = _concordance_summary_statistics(event_times, predicted_scores, event_observed)\n",
    "\n",
    "#     return _concordance_ratio(num_correct, num_tied, num_pairs)\n",
    "\n",
    "\n",
    "# def _concordance_ratio(num_correct: int, num_tied: int, num_pairs: int) -> float:\n",
    "#     if num_pairs == 0:\n",
    "#         raise ZeroDivisionError(\"No admissable pairs in the dataset.\")\n",
    "#     return (num_correct + num_tied / 2) / num_pairs\n",
    "\n",
    "\n",
    "# def _concordance_summary_statistics(event_times, predicted_event_times, event_observed):  # pylint: disable=too-many-locals\n",
    "#     \"\"\"Find the concordance index in n * log(n) time.\n",
    "\n",
    "#     Assumes the data has been verified by lifelines.utils.concordance_index first.\n",
    "#     \"\"\"\n",
    "#     # Here's how this works.\n",
    "#     #\n",
    "#     # It would be pretty easy to do if we had no censored data and no ties. There, the basic idea\n",
    "#     # would be to iterate over the cases in order of their true event time (from least to greatest),\n",
    "#     # while keeping track of a pool of *predicted* event times for all cases previously seen (= all\n",
    "#     # cases that we know should be ranked lower than the case we're looking at currently).\n",
    "#     #\n",
    "#     # If the pool has O(log n) insert and O(log n) RANK (i.e., \"how many things in the pool have\n",
    "#     # value less than x\"), then the following algorithm is n log n:\n",
    "#     #\n",
    "#     # Sort the times and predictions by time, increasing\n",
    "#     # n_pairs, n_correct := 0\n",
    "#     # pool := {}\n",
    "#     # for each prediction p:\n",
    "#     #     n_pairs += len(pool)\n",
    "#     #     n_correct += rank(pool, p)\n",
    "#     #     add p to pool\n",
    "#     #\n",
    "#     # There are three complications: tied ground truth values, tied predictions, and censored\n",
    "#     # observations.\n",
    "#     #\n",
    "#     # - To handle tied true event times, we modify the inner loop to work in *batches* of observations\n",
    "#     # p_1, ..., p_n whose true event times are tied, and then add them all to the pool\n",
    "#     # simultaneously at the end.\n",
    "#     #\n",
    "#     # - To handle tied predictions, which should each count for 0.5, we switch to\n",
    "#     #     n_correct += min_rank(pool, p)\n",
    "#     #     n_tied += count(pool, p)\n",
    "#     #\n",
    "#     # - To handle censored observations, we handle each batch of tied, censored observations just\n",
    "#     # after the batch of observations that died at the same time (since those censored observations\n",
    "#     # are comparable all the observations that died at the same time or previously). However, we do\n",
    "#     # NOT add them to the pool at the end, because they are NOT comparable with any observations\n",
    "#     # that leave the study afterward--whether or not those observations get censored.\n",
    "#     if np.logical_not(event_observed).all():\n",
    "#         return (0, 0, 0)\n",
    "\n",
    "#     died_mask = event_observed.astype(bool)\n",
    "#     # TODO: is event_times already sorted? That would be nice...\n",
    "#     died_truth = event_times[died_mask]\n",
    "#     ix = np.argsort(died_truth)\n",
    "#     died_truth = died_truth[ix]\n",
    "#     died_pred = predicted_event_times[died_mask][ix]\n",
    "\n",
    "#     censored_truth = event_times[~died_mask]\n",
    "#     ix = np.argsort(censored_truth)\n",
    "#     censored_truth = censored_truth[ix]\n",
    "#     censored_pred = predicted_event_times[~died_mask][ix]\n",
    "\n",
    "#     censored_ix = 0\n",
    "#     died_ix = 0\n",
    "#     times_to_compare = _BTree(np.unique(died_pred))\n",
    "#     num_pairs = np.int64(0)\n",
    "#     num_correct = np.int64(0)\n",
    "#     num_tied = np.int64(0)\n",
    "\n",
    "#     # we iterate through cases sorted by exit time:\n",
    "#     # - First, all cases that died at time t0. We add these to the sortedlist of died times.\n",
    "#     # - Then, all cases that were censored at time t0. We DON'T add these since they are NOT\n",
    "#     #   comparable to subsequent elements.\n",
    "#     while True:\n",
    "#         has_more_censored = censored_ix < len(censored_truth)\n",
    "#         has_more_died = died_ix < len(died_truth)\n",
    "#         # Should we look at some censored indices next, or died indices?\n",
    "#         if has_more_censored and (not has_more_died or died_truth[died_ix] > censored_truth[censored_ix]):\n",
    "#             pairs, correct, tied, next_ix = _handle_pairs(censored_truth, censored_pred, censored_ix, times_to_compare)\n",
    "#             censored_ix = next_ix\n",
    "#         elif has_more_died and (not has_more_censored or died_truth[died_ix] <= censored_truth[censored_ix]):\n",
    "#             pairs, correct, tied, next_ix = _handle_pairs(died_truth, died_pred, died_ix, times_to_compare)\n",
    "#             for pred in died_pred[died_ix:next_ix]:\n",
    "#                 times_to_compare.insert(pred)\n",
    "#             died_ix = next_ix\n",
    "#         else:\n",
    "#             assert not (has_more_died or has_more_censored)\n",
    "#             break\n",
    "\n",
    "#         num_pairs += pairs\n",
    "#         num_correct += correct\n",
    "#         num_tied += tied\n",
    "\n",
    "#     return (num_correct, num_tied, num_pairs)\n",
    "\n",
    "\n",
    "# def _handle_pairs(truth, pred, first_ix, times_to_compare):\n",
    "#     \"\"\"\n",
    "#     Handle all pairs that exited at the same time as truth[first_ix].\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#       (pairs, correct, tied, next_ix)\n",
    "#       new_pairs: The number of new comparisons performed\n",
    "#       new_correct: The number of comparisons correctly predicted\n",
    "#       next_ix: The next index that needs to be handled\n",
    "#     \"\"\"\n",
    "#     next_ix = first_ix\n",
    "#     while next_ix < len(truth) and truth[next_ix] == truth[first_ix]:\n",
    "#         next_ix += 1\n",
    "#     pairs = len(times_to_compare) * (next_ix - first_ix)\n",
    "#     correct = np.int64(0)\n",
    "#     tied = np.int64(0)\n",
    "#     for i in range(first_ix, next_ix):\n",
    "#         rank, count = times_to_compare.rank(pred[i])\n",
    "#         correct += rank\n",
    "#         tied += count\n",
    "\n",
    "#     return (pairs, correct, tied, next_ix)\n",
    "\n",
    "\n",
    "# def _naive_concordance_summary_statistics(event_times, predicted_event_times, event_observed):\n",
    "#     \"\"\"\n",
    "#     Fallback, simpler method to compute concordance.\n",
    "\n",
    "#     \"\"\"\n",
    "\n",
    "#     def _valid_comparison(time_a, time_b, event_a, event_b):\n",
    "#         \"\"\"True if times can be compared.\"\"\"\n",
    "#         if time_a == time_b:\n",
    "#             # Ties are only informative if exactly one event happened\n",
    "#             return event_a != event_b\n",
    "#         if event_a and event_b:\n",
    "#             return True\n",
    "#         if event_a and time_a < time_b:\n",
    "#             return True\n",
    "#         if event_b and time_b < time_a:\n",
    "#             return True\n",
    "#         return False\n",
    "\n",
    "#     def _concordance_value(time_a, time_b, pred_a, pred_b, event_a, event_b):\n",
    "#         if pred_a == pred_b:\n",
    "#             # Same as random\n",
    "#             return (0, 1)\n",
    "#         if pred_a < pred_b:\n",
    "#             return (time_a < time_b) or (time_a == time_b and event_a and not event_b), 0\n",
    "#         # pred_a > pred_b\n",
    "#         return (time_a > time_b) or (time_a == time_b and not event_a and event_b), 0\n",
    "\n",
    "#     num_pairs = 0.0\n",
    "#     num_correct = 0.0\n",
    "#     num_tied = 0.0\n",
    "\n",
    "#     for a, time_a in enumerate(event_times):\n",
    "#         pred_a = predicted_event_times[a]\n",
    "#         event_a = event_observed[a]\n",
    "#         # Don't want to double count\n",
    "#         for b in range(a + 1, len(event_times)):\n",
    "#             time_b = event_times[b]\n",
    "#             pred_b = predicted_event_times[b]\n",
    "#             event_b = event_observed[b]\n",
    "\n",
    "#             if _valid_comparison(time_a, time_b, event_a, event_b):\n",
    "#                 num_pairs += 1.0\n",
    "#                 crct, ties = _concordance_value(time_a, time_b, pred_a, pred_b, event_a, event_b)\n",
    "#                 num_correct += crct\n",
    "#                 num_tied += ties\n",
    "\n",
    "#     return (num_correct, num_tied, num_pairs)\n",
    "\n",
    "\n",
    "# def naive_concordance_index(event_times, predicted_event_times, event_observed=None) -> float:\n",
    "#     event_times, predicted_event_times, event_observed = _preprocess_scoring_data(\n",
    "#         event_times, predicted_event_times, event_observed\n",
    "#     )\n",
    "#     return _concordance_ratio(*_naive_concordance_summary_statistics(event_times, predicted_event_times, event_observed))\n",
    "\n",
    "\n",
    "# def _preprocess_scoring_data(event_times, predicted_scores, event_observed):\n",
    "#     event_times = np.asarray(event_times, dtype=float)\n",
    "#     predicted_scores = np.asarray(predicted_scores, dtype=float)\n",
    "\n",
    "#     # Allow for (n, 1) or (1, n) arrays\n",
    "#     if event_times.ndim == 2 and (event_times.shape[0] == 1 or event_times.shape[1] == 1):\n",
    "#         # Flatten array\n",
    "#         event_times = event_times.ravel()\n",
    "#     # Allow for (n, 1) or (1, n) arrays\n",
    "#     if predicted_scores.ndim == 2 and (predicted_scores.shape[0] == 1 or predicted_scores.shape[1] == 1):\n",
    "#         # Flatten array\n",
    "#         predicted_scores = predicted_scores.ravel()\n",
    "\n",
    "#     if event_times.shape != predicted_scores.shape:\n",
    "#         raise ValueError(\"Event times and predictions must have the same shape\")\n",
    "#     if event_times.ndim != 1:\n",
    "#         raise ValueError(\"Event times can only be 1-dimensional: (n,)\")\n",
    "\n",
    "#     if event_observed is None:\n",
    "#         event_observed = np.ones(event_times.shape[0], dtype=float)\n",
    "#     else:\n",
    "#         event_observed = np.asarray(event_observed, dtype=float).ravel()\n",
    "#         if event_observed.shape != event_times.shape:\n",
    "#             raise ValueError(\"Observed events must be 1-dimensional of same length as event times\")\n",
    "\n",
    "#     # check for NaNs\n",
    "#     for a in [event_times, predicted_scores, event_observed]:\n",
    "#         if np.isnan(a).any():\n",
    "#             raise ValueError(\"NaNs detected in inputs, please correct or drop.\")\n",
    "\n",
    "#     return event_times, predicted_scores, event_observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "628cb5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- iPython Config --- ###\n",
    "from IPython import get_ipython\n",
    "if 'IPython.extensions.autoreload' not in get_ipython().extension_manager.loaded:\n",
    "    get_ipython().run_line_magic('load_ext', 'autoreload')\n",
    "else:\n",
    "    get_ipython().run_line_magic('reload_ext', 'autoreload')\n",
    "%autoreload 2\n",
    "### --- System and Path --- ###\n",
    "import os\n",
    "import sys\n",
    "repo_path = os.path.dirname(os.getcwd())\n",
    "if repo_path not in sys.path:\n",
    "    sys.path.append(repo_path)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from lifelines.utils import concordance_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb19353a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KERNEL_RUN_TYPE: local\n"
     ]
    }
   ],
   "source": [
    "# Configs\n",
    "SEED = 42\n",
    "kernel_run_type = \"kaggle\" if \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ else \"local\"\n",
    "print(f\"KERNEL_RUN_TYPE: {kernel_run_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efa56f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "if kernel_run_type==\"kaggle\":\n",
    "    df_train = pd.read_csv('/kaggle/input/equity-post-HCT-survival-predictions/train.csv')\n",
    "    df_test = pd.read_csv('/kaggle/input/equity-post-HCT-survival-predictions/test.csv')\n",
    "else:\n",
    "    # local\n",
    "    df_train = pd.read_csv(os.path.join(repo_path, 'data', 'raw', 'train.csv'))\n",
    "    df_test = pd.read_csv(os.path.join(repo_path, 'data', 'raw', 'test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21f4e479",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_measurement_scales= {\n",
    "    # numerical\n",
    "    'age_at_hct': 'numerical',\n",
    "    'donor_age': 'numerical',\n",
    "    # cat-ordinal\n",
    "    'dri_score': 'ordinal',\n",
    "    'cyto_score': 'ordinal',\n",
    "    'cyto_score_detail': 'ordinal',\n",
    "    'conditioning_intensity': 'ordinal',\n",
    "    # cat-nominal\n",
    "    'hla_match_c_high': 'nominal',\n",
    "    'hla_high_res_8': 'nominal',\n",
    "    'hla_low_res_6': 'nominal',\n",
    "    'hla_high_res_6': 'nominal',\n",
    "    'hla_high_res_10': 'nominal',\n",
    "    'hla_match_dqb1_high': 'nominal',\n",
    "    'hla_nmdp_6': 'nominal',\n",
    "    'hla_match_c_low': 'nominal',\n",
    "    'hla_match_drb1_low': 'nominal',\n",
    "    'hla_match_dqb1_low': 'nominal',\n",
    "    'hla_match_a_high': 'nominal',\n",
    "    'hla_match_b_low': 'nominal',\n",
    "    'hla_match_a_low': 'nominal',\n",
    "    'hla_match_b_high': 'nominal',\n",
    "    'comorbidity_score': 'nominal',\n",
    "    'karnofsky_score': 'nominal',\n",
    "    'hla_low_res_8': 'nominal',\n",
    "    'hla_match_drb1_high': 'nominal',\n",
    "    'hla_low_res_10': 'nominal',\n",
    "    'ID': 'nominal',\n",
    "    'psych_disturb': 'nominal',\n",
    "    'diabetes': 'nominal',\n",
    "    'tbi_status': 'nominal',\n",
    "    'arrhythmia': 'nominal',\n",
    "    'graft_type': 'nominal',\n",
    "    'vent_hist': 'nominal',\n",
    "    'renal_issue': 'nominal',\n",
    "    'pulm_severe': 'nominal',\n",
    "    'prim_disease_hct': 'nominal',\n",
    "    'cmv_status': 'nominal',\n",
    "    'tce_imm_match': 'nominal',\n",
    "    'rituximab': 'nominal',\n",
    "    'prod_type': 'nominal',\n",
    "    'ethnicity': 'nominal',\n",
    "    'year_hct': 'nominal',\n",
    "    'obesity': 'nominal',\n",
    "    'mrd_hct': 'nominal',\n",
    "    'in_vivo_tcd': 'nominal',\n",
    "    'tce_match': 'nominal',\n",
    "    'hepatic_severe': 'nominal',\n",
    "    'prior_tumor': 'nominal',\n",
    "    'peptic_ulcer': 'nominal',\n",
    "    'gvhd_proph': 'nominal',\n",
    "    'rheum_issue': 'nominal',\n",
    "    'sex_match': 'nominal',\n",
    "    'race_group': 'nominal',\n",
    "    'hepatic_mild': 'nominal',\n",
    "    'tce_div_match': 'nominal',\n",
    "    'donor_related': 'nominal',\n",
    "    'melphalan_dose': 'nominal',\n",
    "    'cardiac': 'nominal',\n",
    "    'pulm_moderate': 'nominal',\n",
    "    # target\n",
    "    'efs': 'nominal', # binary target\n",
    "    'efs_time': 'numerical', # time\n",
    "}\n",
    "# categorical_cols = [col for col, scale in cols_measurement_scales.items() if scale in ['nominal', 'ordinal']]\n",
    "# nominal_cols = [col for col, scale in cols_measurement_scales.items() if scale in ['nominal']]\n",
    "# ordinal_cols = [col for col, scale in cols_measurement_scales.items() if scale in ['ordinal']]\n",
    "# numerical_cols = [col for col, scale in cols_measurement_scales.items() if scale in ['numerical']]\n",
    "\n",
    "# # Check\n",
    "# assert set(df_train.columns) == set(cols_measurement_scales.keys())\n",
    "# assert len(cols_measurement_scales) == len(categorical_cols) + len(numerical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe397ca8",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e8a8de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'numerical'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lifelines import KaplanMeierFitter\n",
    "def transform_survival_probability(df, time_col='efs_time', event_col='efs'):\n",
    "    kmf = KaplanMeierFitter()\n",
    "    kmf.fit(df[time_col], df[event_col])\n",
    "    y = kmf.survival_function_at_times(df[time_col]).values\n",
    "    return y\n",
    "df_train[\"target\"] = transform_survival_probability(df_train, time_col='efs_time', event_col='efs')\n",
    "efs_time = df_train['efs_time']  # Extract survival times for C-index calculation\n",
    "# drop\n",
    "df_train = df_train.drop(columns=['efs', 'efs_time'])\n",
    "cols_measurement_scales.pop('efs')\n",
    "cols_measurement_scales.pop('efs_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16b54be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns\n",
    "cols = ['ID']\n",
    "cols_measurement_scales.pop('ID')\n",
    "# categorical_cols.remove('ID')\n",
    "# nominal_cols.remove('ID')\n",
    "id_df_test = df_test['ID']  # For submission\n",
    "\n",
    "df_train.drop(cols, axis=1, inplace=True)\n",
    "df_test.drop(cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e1b8f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "target = 'target'\n",
    "\n",
    "# train dataset\n",
    "X_train = df_train.drop([target], axis=1)\n",
    "y_train = df_train[target]\n",
    "# test dataset\n",
    "X_test = df_test  # No target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de8fa306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fillna with 'UNK'\n",
    "cat_cols = [col for col, scale in cols_measurement_scales.items() if scale in ['nominal', 'ordinal']]\n",
    "X_train[cat_cols] = X_train[cat_cols].fillna('UNK').astype(str)\n",
    "X_test[cat_cols] = X_test[cat_cols].fillna('UNK').astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36500336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHotEncoding\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def one_hot_encoding(X_train, X_test, cat_cols=None):\n",
    "    # Identify categorical and numerical columns\n",
    "    num_cols = X_train.columns.difference(cat_cols)\n",
    "\n",
    "    # Apply OneHotEncoding\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "    X_train_cat = ohe.fit_transform(X_train[cat_cols])\n",
    "    X_test_cat = ohe.transform(X_test[cat_cols])\n",
    "\n",
    "    # Convert OHE to DataFrame and maintain column names\n",
    "    X_train_cat = pd.DataFrame(X_train_cat, columns=ohe.get_feature_names_out(), index=X_train.index)\n",
    "    X_test_cat = pd.DataFrame(X_test_cat, columns=ohe.get_feature_names_out(), index=X_test.index)\n",
    "\n",
    "    # Concatenate with Numerical columns\n",
    "    X_train_final = pd.concat([X_train[num_cols].reset_index(drop=True), X_train_cat.reset_index(drop=True)], axis=1)\n",
    "    X_test_final = pd.concat([X_test[num_cols].reset_index(drop=True), X_test_cat.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    # Ensure the same feature set between train and test\n",
    "    X_test_final = X_test_final.reindex(columns=X_train_final.columns, fill_value=0)\n",
    "\n",
    "    return X_train_final, X_test_final\n",
    "\n",
    "X_train, X_test = one_hot_encoding(X_train.copy(), X_test.copy(), cat_cols=[col for col, scale in cols_measurement_scales.items() if scale in ['nominal', 'ordinal']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b58de3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "\n",
    "def encode_nominal_features(X_train, X_test, nominal_cols):\n",
    "    \"\"\"\n",
    "    Encodes nominal categorical features using LabelEncoder.\n",
    "\n",
    "    Parameters:\n",
    "    - X_train (pd.DataFrame): Training dataset.\n",
    "    - X_test (pd.DataFrame): Test dataset.\n",
    "    - categorical_cols (list): List of nominal categorical columns.\n",
    "\n",
    "    Returns:\n",
    "    - X_train_encoded (pd.DataFrame): Transformed training dataset with encoded nominal features.\n",
    "    - X_test_encoded (pd.DataFrame): Transformed test dataset with encoded nominal features.\n",
    "    \"\"\"\n",
    "    X_train_encoded, X_test_encoded = X_train.copy(), X_test.copy()\n",
    "\n",
    "    for col in nominal_cols:\n",
    "        le = LabelEncoder()\n",
    "        X_train_encoded[col] = le.fit_transform(X_train_encoded[col].astype(str))\n",
    "        X_test_encoded[col] = le.transform(X_test_encoded[col].astype(str))\n",
    "\n",
    "    return X_train_encoded, X_test_encoded\n",
    "\n",
    "def encode_ordinal_features(X_train, X_test, ordinal_cols):\n",
    "    \"\"\"\n",
    "    Encodes ordinal categorical features using OrdinalEncoder.\n",
    "    \"\"\"\n",
    "    X_train_encoded, X_test_encoded = X_train.copy(), X_test.copy()\n",
    "\n",
    "    for col in ordinal_cols:\n",
    "        oe = OrdinalEncoder()\n",
    "        X_train_encoded[col] = oe.fit_transform(X_train_encoded[[col]].astype(str))\n",
    "        X_test_encoded[col] = oe.transform(X_test_encoded[[col]].astype(str))\n",
    "\n",
    "    return X_train_encoded, X_test_encoded\n",
    "\n",
    "# X_train, X_test = encode_nominal_features(X_train, X_test, nominal_cols)\n",
    "# X_train, X_test = encode_ordinal_features(X_train, X_test, ordinal_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7acdd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def scale_to_standard(X_train, X_test, num_cols=None):\n",
    "    \"\"\"\n",
    "    Scales numerical features to standard normal distribution (mean=0, std=1).\n",
    "    \"\"\"\n",
    "\n",
    "    # Apply Standard Scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train[num_cols])\n",
    "    X_test_scaled = scaler.transform(X_test[num_cols])\n",
    "\n",
    "    # Convert back to DataFrame\n",
    "    X_train_scaled = pd.DataFrame(X_train_scaled, columns=num_cols, index=X_train.index)\n",
    "    X_test_scaled = pd.DataFrame(X_test_scaled, columns=num_cols, index=X_test.index)\n",
    "\n",
    "    # Replace original numerical features with scaled ones\n",
    "    X_train_final = X_train.copy()\n",
    "    X_test_final = X_test.copy()\n",
    "    X_train_final[num_cols] = X_train_scaled\n",
    "    X_test_final[num_cols] = X_test_scaled\n",
    "\n",
    "    return X_train_final, X_test_final\n",
    "\n",
    "# Apply the transformation\n",
    "X_train, X_test = scale_to_standard(X_train.copy(), X_test.copy(), num_cols=[col for col, scale in cols_measurement_scales.items() if scale in ['numerical']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6231ac",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5231361",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T17:18:29.992554Z",
     "iopub.status.busy": "2025-02-02T17:18:29.992068Z",
     "iopub.status.idle": "2025-02-02T17:22:30.524401Z",
     "shell.execute_reply": "2025-02-02T17:22:30.523306Z"
    },
    "papermill": {
     "duration": 240.537606,
     "end_time": "2025-02-02T17:22:30.526545",
     "exception": false,
     "start_time": "2025-02-02T17:18:29.988939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import optuna\n",
    "# from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "# from sklearn.model_selection import StratifiedKFold, KFold\n",
    "# from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# # Parameters\n",
    "# DEFAULT_ITERATIONS = 10_000\n",
    "# VERBOSE = 2_000\n",
    "# train_dir = os.path.join(repo_path, \"models\", \"catboost_info\")\n",
    "# os.makedirs(train_dir, exist_ok=True)\n",
    "\n",
    "# base_params = {\n",
    "#     # \"loss_function\": \"Logloss\",\n",
    "#     \"train_dir\": train_dir,\n",
    "#     \"iterations\": DEFAULT_ITERATIONS,\n",
    "#     \"verbose\": VERBOSE,\n",
    "#     \"random_state\": SEED,\n",
    "# }\n",
    "\n",
    "# def objective(trial):\n",
    "#     \"\"\"\n",
    "#     Optuna optimization using C-index as the evaluation criterion.\n",
    "#     \"\"\"\n",
    "\n",
    "#     learnable_params = {\n",
    "#         \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 5e-3, 2e-1),\n",
    "#         \"depth\": trial.suggest_int(\"depth\", 5, 8),\n",
    "#         \"l2_leaf_reg\": trial.suggest_uniform(\"l2_leaf_reg\", 1, 5),\n",
    "#     }\n",
    "\n",
    "#     params = {**base_params, **learnable_params}\n",
    "#     model = CatBoostRegressor(**params)\n",
    "\n",
    "#     cv_folds = 3\n",
    "#     # cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=SEED)\n",
    "#     cv = KFold(n_splits=cv_folds, shuffle=True, random_state=SEED)\n",
    "#     fold_scores = []\n",
    "#     print(f\"Starting cross-validation for trial: {trial.number+1}\")\n",
    "#     for fold, (train_idx, val_idx) in tqdm(enumerate(cv.split(X_train, y_train), 1), total=cv_folds):\n",
    "#         # print(f\"Trial {trial.number}, Fold {fold}: Training the model...\")\n",
    "\n",
    "#         x_tr, x_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "#         y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "#         efs_time_val = efs_time.iloc[val_idx]  # Get survival times for validation\n",
    "\n",
    "#         # Train model\n",
    "#         model.fit(x_tr, y_tr)\n",
    "\n",
    "#         # Predict risk scores (probabilities)\n",
    "#         # y_pred_proba = model.predict_proba(x_val)[:, 1]  # Higher values mean higher risk\n",
    "#         y_pred = model.predict(x_val)\n",
    "\n",
    "#         # Compute Concordance Index\n",
    "#         c_index = concordance_index(efs_time_val, -y_pred, y_val)  # Negative for risk interpretation\n",
    "#         print(f\"Trial {trial.number+1}, Fold {fold}: C-Index={c_index}\")\n",
    "#         fold_scores.append(c_index)\n",
    "\n",
    "#     return np.mean(fold_scores)  # Maximizing mean C-index\n",
    "\n",
    "# # Print results\n",
    "# def print_optuna_results(study):\n",
    "#     print(\"Number of finished trials:\", len(study.trials))\n",
    "#     print(\"Best trial:\")\n",
    "#     trial_ = study.best_trial\n",
    "#     print(\"  Best C-index:\", trial_.value)\n",
    "#     print(\"  Params: \")\n",
    "#     for key, value in trial_.params.items():\n",
    "#         print(f\"    {key}: {value}\")\n",
    "\n",
    "\n",
    "# # Running the optimization...\n",
    "# n_trials = 3\n",
    "# study = optuna.create_study(direction=\"maximize\")\n",
    "# study.optimize(objective, n_trials=n_trials, show_progress_bar=False, timeout=None)\n",
    "# print_optuna_results(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c89b7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-23 14:12:26,454] A new study created in memory with name: no-name-596ec423-3abe-4e55-a01c-9fe0b4fc0ac6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting cross-validation for trial: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:03<00:06,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1, Fold 1: C-Index=0.648857531585834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:06<00:03,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1, Fold 2: C-Index=0.6467120600682004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:10<00:00,  3.39s/it]\n",
      "[I 2025-02-23 14:12:36,639] Trial 0 finished with value: 0.6454145348618674 and parameters: {}. Best is trial 0 with value: 0.6454145348618674.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1, Fold 3: C-Index=0.6406740129315678\n",
      "Starting cross-validation for trial: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:03<00:06,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2, Fold 1: C-Index=0.648857531585834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:06<00:03,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2, Fold 2: C-Index=0.6467120600682004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:09<00:00,  3.24s/it]\n",
      "[I 2025-02-23 14:12:46,349] Trial 1 finished with value: 0.6454145348618674 and parameters: {}. Best is trial 0 with value: 0.6454145348618674.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2, Fold 3: C-Index=0.6406740129315678\n",
      "Starting cross-validation for trial: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:03<00:06,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3, Fold 1: C-Index=0.648857531585834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:06<00:03,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3, Fold 2: C-Index=0.6467120600682004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:09<00:00,  3.16s/it]\n",
      "[I 2025-02-23 14:12:55,841] Trial 2 finished with value: 0.6454145348618674 and parameters: {}. Best is trial 0 with value: 0.6454145348618674.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3, Fold 3: C-Index=0.6406740129315678\n",
      "Starting cross-validation for trial: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:03<00:06,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4, Fold 1: C-Index=0.648857531585834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:06<00:03,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4, Fold 2: C-Index=0.6467120600682004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:09<00:00,  3.19s/it]\n",
      "[I 2025-02-23 14:13:05,406] Trial 3 finished with value: 0.6454145348618674 and parameters: {}. Best is trial 0 with value: 0.6454145348618674.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4, Fold 3: C-Index=0.6406740129315678\n",
      "Starting cross-validation for trial: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:03<00:06,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5, Fold 1: C-Index=0.648857531585834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:06<00:03,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5, Fold 2: C-Index=0.6467120600682004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:09<00:00,  3.22s/it]\n",
      "[I 2025-02-23 14:13:15,070] Trial 4 finished with value: 0.6454145348618674 and parameters: {}. Best is trial 0 with value: 0.6454145348618674.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5, Fold 3: C-Index=0.6406740129315678\n",
      "Number of finished trials: 5\n",
      "Best trial:\n",
      "  Best C-index: 0.6454145348618674\n",
      "  Params: \n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Parameters\n",
    "DEFAULT_ITERATIONS = 10_000\n",
    "VERBOSE = 2_000\n",
    "train_dir = os.path.join(repo_path, \"models\", \"catboost_info\")\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "\n",
    "base_params = {\n",
    "    # \"loss_function\": \"Logloss\",\n",
    "    \"train_dir\": train_dir,\n",
    "    \"iterations\": DEFAULT_ITERATIONS,\n",
    "    \"verbose\": VERBOSE,\n",
    "    \"random_state\": SEED,\n",
    "    \"max_depth\": 3,\n",
    "    \"colsample_bytree\": 0.5,\n",
    "    \"subsample\": 0.8,\n",
    "    \"n_estimators\": 2000,\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"enable_categorical\": True,\n",
    "    \"min_child_weight\": 80,\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Optuna optimization using C-index as the evaluation criterion.\n",
    "    \"\"\"\n",
    "\n",
    "    learnable_params = {\n",
    "        # \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 5e-3, 2e-1),\n",
    "        # \"depth\": trial.suggest_int(\"depth\", 5, 8),\n",
    "        # \"l2_leaf_reg\": trial.suggest_uniform(\"l2_leaf_reg\", 1, 5),\n",
    "    }\n",
    "\n",
    "    params = {**base_params, **learnable_params}\n",
    "    model = XGBRegressor(**params)\n",
    "\n",
    "    cv_folds = 3\n",
    "    # cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=SEED)\n",
    "    cv = KFold(n_splits=cv_folds, shuffle=True, random_state=SEED)\n",
    "    fold_scores = []\n",
    "    print(f\"Starting cross-validation for trial: {trial.number+1}\")\n",
    "    for fold, (train_idx, val_idx) in tqdm(enumerate(cv.split(X_train, y_train), 1), total=cv_folds):\n",
    "        # print(f\"Trial {trial.number}, Fold {fold}: Training the model...\")\n",
    "\n",
    "        x_tr, x_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        efs_time_val = efs_time.iloc[val_idx]  # Get survival times for validation\n",
    "\n",
    "        # Train model\n",
    "        model.fit(np.array(x_tr), np.array(y_tr))\n",
    "\n",
    "        # Predict risk scores (probabilities)\n",
    "        # y_pred_proba = model.predict_proba(x_val)[:, 1]  # Higher values mean higher risk\n",
    "        y_pred = model.predict(x_val)\n",
    "\n",
    "        # Compute Concordance Index\n",
    "        c_index = concordance_index(efs_time_val, -y_pred, y_val)  # Negative for risk interpretation\n",
    "        print(f\"Trial {trial.number+1}, Fold {fold}: C-Index={c_index}\")\n",
    "        fold_scores.append(c_index)\n",
    "\n",
    "    return np.mean(fold_scores)  # Maximizing mean C-index\n",
    "\n",
    "# Print results\n",
    "def print_optuna_results(study):\n",
    "    print(\"Number of finished trials:\", len(study.trials))\n",
    "    print(\"Best trial:\")\n",
    "    trial_ = study.best_trial\n",
    "    print(\"  Best C-index:\", trial_.value)\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial_.params.items():\n",
    "        print(f\"    {key}: {value}\")\n",
    "\n",
    "\n",
    "# Running the optimization...\n",
    "n_trials = 5\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=n_trials, show_progress_bar=False, timeout=None)\n",
    "print_optuna_results(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42d4e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train the final model with best parameters\n",
    "# # best_learnable_params = study.best_params\n",
    "# best_learnable_params = {}\n",
    "# params = {**base_params, **best_learnable_params}\n",
    "# final_model = CatBoostRegressor(**params)\n",
    "\n",
    "# # Fitting final model...\n",
    "# final_model.fit(X_train, y_train)\n",
    "\n",
    "# # Save the model\n",
    "# if kernel_run_type==\"kaggle\":\n",
    "#     filepath = ''\n",
    "# else:\n",
    "#     time_now = time.strftime(\"%Y%m%d-%H%M\")\n",
    "#     filepath = os.path.join(repo_path, \"models\", f\"{time_now}-model.pkl\")\n",
    "# joblib.dump(final_model, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20d62ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/pupipatsingkhorn/Developer/repositories/CIBMTR-equity-post-HCT-survival-predictions/models/20250223-1413-model.pkl']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the final model with best parameters\n",
    "best_learnable_params = study.best_params\n",
    "# best_learnable_params = {}\n",
    "params = {**base_params, **best_learnable_params}\n",
    "final_model = XGBRegressor(**params)\n",
    "\n",
    "# Fitting final model...\n",
    "final_model.fit(np.array(X_train), np.array(y_train))\n",
    "\n",
    "# Save the model\n",
    "if kernel_run_type==\"kaggle\":\n",
    "    filepath = ''\n",
    "else:\n",
    "    time_now = time.strftime(\"%Y%m%d-%H%M\")\n",
    "    filepath = os.path.join(repo_path, \"models\", f\"{time_now}-model.pkl\")\n",
    "joblib.dump(final_model, filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96ed8fa",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d2581ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load final model\n",
    "if kernel_run_type==\"kaggle\":\n",
    "    # change here\n",
    "    filepath = '/kaggle/input/20250204-2157-model.pkl/scikitlearn/default/1/20250204-2157-model.pkl'\n",
    "else: # local\n",
    "    model_name = \"20250223-1413-model.pkl\" # change here\n",
    "    filepath = os.path.join(repo_path, \"models\", model_name)\n",
    "final_model = joblib.load(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54fa4534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved on local successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "prediction",
         "rawType": "float32",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "4354206c-c85a-4392-bea9-81332535a2f8",
       "rows": [
        [
         "0",
         "28800",
         "0.5016696"
        ],
        [
         "1",
         "28801",
         "0.6250088"
        ],
        [
         "2",
         "28802",
         "0.44464344"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28800</td>\n",
       "      <td>0.501670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28801</td>\n",
       "      <td>0.625009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28802</td>\n",
       "      <td>0.444643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  prediction\n",
       "0  28800    0.501670\n",
       "1  28801    0.625009\n",
       "2  28802    0.444643"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inference\n",
    "# y_pred_proba = final_model.predict_proba(X_test)[:, 1]  # Probability of event occurring\n",
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "# Save submission\n",
    "df_submission = pd.DataFrame({'ID': id_df_test, 'prediction': y_pred})\n",
    "if kernel_run_type==\"kaggle\":\n",
    "    df_submission.to_csv('submission.csv', index=False)\n",
    "else:\n",
    "    # local\n",
    "    # main file:\n",
    "    filepath = os.path.join(repo_path, 'data', 'submission', 'submission.csv')\n",
    "    df_submission.to_csv(filepath, index=False)\n",
    "    # archive file:\n",
    "    time_now = time.strftime(\"%Y%m%d-%H%M\")\n",
    "    filepath = os.path.join(repo_path, 'data', 'submission', 'archive', f'{time_now}-submission.csv')\n",
    "    df_submission.to_csv(filepath, index=False)\n",
    "print(f\"Submission saved on {kernel_run_type} successfully.\")\n",
    "\n",
    "df_submission"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 10381525,
     "sourceId": 70942,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 244.250158,
   "end_time": "2025-02-02T17:22:31.352616",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-02T17:18:27.102458",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1256232a33fa4888a7f96230439e2c76": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2f70d247e98442a0bff0a9f4e651031a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f456bd28218b48ca8a0abb1a163306e5",
        "IPY_MODEL_348fb90e32534922ae866a89c1535cea",
        "IPY_MODEL_99c2aa12d63040d7b60448dc449b7cc6"
       ],
       "layout": "IPY_MODEL_a372d2ca55da443ab6e8aae9f29934f1",
       "tabbable": null,
       "tooltip": null
      }
     },
     "348fb90e32534922ae866a89c1535cea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_548558cadb21425fa3fef9305a927579",
       "max": 7,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3543bcb390944447adc4386a7e5ba51f",
       "tabbable": null,
       "tooltip": null,
       "value": 7
      }
     },
     "3543bcb390944447adc4386a7e5ba51f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3ca0c22c7fb941f783d6b92de7b73668": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "548558cadb21425fa3fef9305a927579": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "99c2aa12d63040d7b60448dc449b7cc6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1256232a33fa4888a7f96230439e2c76",
       "placeholder": "​",
       "style": "IPY_MODEL_bfe67bb1596d48cabb27d337b9657ef5",
       "tabbable": null,
       "tooltip": null,
       "value": " 7/7 [03:49&lt;00:00, 51.89s/it]"
      }
     },
     "9bd3cf423c1f4d308c5a9c8d7cb2de68": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a372d2ca55da443ab6e8aae9f29934f1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bfe67bb1596d48cabb27d337b9657ef5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f456bd28218b48ca8a0abb1a163306e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9bd3cf423c1f4d308c5a9c8d7cb2de68",
       "placeholder": "​",
       "style": "IPY_MODEL_3ca0c22c7fb941f783d6b92de7b73668",
       "tabbable": null,
       "tooltip": null,
       "value": "Best trial: 2. Best value: 0.662272: 100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
